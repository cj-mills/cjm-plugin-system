{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Remote Plugin Proxy\n",
    "\n",
    "> Bridge between Host application and isolated Worker processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "default-exp",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core.proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hide-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exports",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import json\n",
    "import os\n",
    "import socket\n",
    "import subprocess\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Any, AsyncGenerator, Dict, Generator, Optional\n",
    "\n",
    "import httpx\n",
    "\n",
    "from cjm_plugin_system.core.interface import FileBackedDTO, PluginInterface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overview",
   "metadata": {},
   "source": [
    "The `RemotePluginProxy` implements `PluginInterface` but forwards all calls over HTTP to a Worker process running in an isolated environment.\n",
    "\n",
    "```\n",
    "Host Application                        Isolated Environment\n",
    "┌────────────────────┐                 ┌─────────────────────┐\n",
    "│  PluginManager     │                 │  Conda Env (GPU)    │\n",
    "│    │               │                 │    │                │\n",
    "│    ▼               │     HTTP        │    ▼                │\n",
    "│  RemotePluginProxy │◄───────────────▶│  Universal Worker   │\n",
    "│  (implements       │   localhost     │    │                │\n",
    "│   PluginInterface) │                 │    ▼                │\n",
    "│                    │                 │  Actual Plugin      │\n",
    "└────────────────────┘                 └─────────────────────┘\n",
    "```\n",
    "\n",
    "Key responsibilities:\n",
    "\n",
    "1. **Process Management**: Launch worker subprocess with correct Python interpreter\n",
    "2. **Port Allocation**: Find free port, pass to worker via CLI\n",
    "3. **Zero-Copy Transfer**: Detect `FileBackedDTO` objects and serialize to temp files\n",
    "4. **Dual Interface**: Sync methods for scripts, async methods for FastHTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proxy-header",
   "metadata": {},
   "source": [
    "## RemotePluginProxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proxy-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RemotePluginProxy(PluginInterface):\n",
    "    \"\"\"Proxy that forwards plugin calls to an isolated Worker subprocess.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        manifest: Dict[str, Any] # Plugin manifest with python_path, module, class, etc.\n",
    "    ):\n",
    "        \"\"\"Initialize proxy and start the worker process.\"\"\"\n",
    "        self.manifest = manifest\n",
    "        self.process: Optional[subprocess.Popen] = None\n",
    "        self.port = self._get_free_port()\n",
    "        self.base_url = f\"http://127.0.0.1:{self.port}\"\n",
    "        self._start_process()\n",
    "\n",
    "    @property\n",
    "    def name(self) -> str: # Plugin name from manifest\n",
    "        \"\"\"Plugin name.\"\"\"\n",
    "        return self.manifest.get('name', 'unknown')\n",
    "    \n",
    "    @property\n",
    "    def version(self) -> str: # Plugin version from manifest\n",
    "        \"\"\"Plugin version.\"\"\"\n",
    "        return self.manifest.get('version', '0.0.0')\n",
    "\n",
    "    def _get_free_port(self) -> int:\n",
    "        \"\"\"Find an available port for the worker.\"\"\"\n",
    "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "            s.bind(('', 0))\n",
    "            return s.getsockname()[1]\n",
    "\n",
    "    def _start_process(self) -> None:\n",
    "        \"\"\"Launch the worker subprocess.\"\"\"\n",
    "        python_path = self.manifest['python_path']\n",
    "        cmd = [\n",
    "            python_path,\n",
    "            \"-m\", \"cjm_plugin_system.core.worker\",\n",
    "            \"--module\", self.manifest['module'],\n",
    "            \"--class\", self.manifest['class'],\n",
    "            \"--port\", str(self.port),\n",
    "            \"--ppid\", str(os.getpid())  # Enable suicide pact\n",
    "        ]\n",
    "        \n",
    "        # Merge environment variables from manifest\n",
    "        env = dict(os.environ)\n",
    "        env.update(self.manifest.get('env_vars', {}))\n",
    "\n",
    "        print(f\"[{self.name}] Starting worker on port {self.port}...\")\n",
    "        self.process = subprocess.Popen(\n",
    "            cmd,\n",
    "            stdout=subprocess.DEVNULL,\n",
    "            stderr=subprocess.PIPE,\n",
    "            start_new_session=True,\n",
    "            env=env\n",
    "        )\n",
    "        self._wait_for_ready()\n",
    "\n",
    "    def _wait_for_ready(\n",
    "        self,\n",
    "        timeout: float = 30.0 # Max seconds to wait for worker startup\n",
    "    ) -> None:\n",
    "        \"\"\"Wait for worker to become responsive.\"\"\"\n",
    "        start = time.time()\n",
    "        while time.time() - start < timeout:\n",
    "            try:\n",
    "                with httpx.Client() as client:\n",
    "                    client.get(f\"{self.base_url}/health\")\n",
    "                print(f\"[{self.name}] Worker ready.\")\n",
    "                return\n",
    "            except httpx.ConnectError:\n",
    "                time.sleep(0.5)\n",
    "        \n",
    "        # Timeout - get stderr for debugging\n",
    "        _, stderr = self.process.communicate(timeout=1)\n",
    "        raise TimeoutError(\n",
    "            f\"Plugin '{self.name}' failed to start within {timeout}s: \"\n",
    "            f\"{stderr.decode() if stderr else 'Unknown error'}\"\n",
    "        )\n",
    "\n",
    "\n",
    "    def initialize(\n",
    "        self,\n",
    "        config: Optional[Dict[str, Any]] = None # Configuration dictionary\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize or reconfigure the plugin.\"\"\"\n",
    "        with httpx.Client() as client:\n",
    "            resp = client.post(f\"{self.base_url}/initialize\", json=config or {})\n",
    "        if resp.status_code != 200:\n",
    "            raise RuntimeError(f\"Initialize failed: {resp.text}\")\n",
    "    \n",
    "    def execute(\n",
    "        self,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ) -> Any: # Plugin result\n",
    "        \"\"\"Execute the plugin synchronously.\"\"\"\n",
    "        payload = self._prepare_payload(args, kwargs)\n",
    "        # timeout=None for long-running AI tasks\n",
    "        with httpx.Client(timeout=None) as client:\n",
    "            resp = client.post(f\"{self.base_url}/execute\", json=payload)\n",
    "        \n",
    "        if resp.status_code != 200:\n",
    "            raise RuntimeError(f\"Execute failed: {resp.text}\")\n",
    "        return resp.json()\n",
    "    \n",
    "    def get_config_schema(self) -> Dict[str, Any]: # JSON Schema\n",
    "        \"\"\"Get the plugin's configuration schema.\"\"\"\n",
    "        with httpx.Client() as client:\n",
    "            return client.get(f\"{self.base_url}/config_schema\").json()\n",
    "    \n",
    "    def get_current_config(self) -> Dict[str, Any]: # Current config values\n",
    "        \"\"\"Get the plugin's current configuration.\"\"\"\n",
    "        with httpx.Client() as client:\n",
    "            return client.get(f\"{self.base_url}/config\").json()\n",
    "\n",
    "\n",
    "    def cleanup(self) -> None:\n",
    "        \"\"\"Clean up plugin resources and terminate worker process.\"\"\"\n",
    "        # Send cleanup request to worker\n",
    "        try:\n",
    "            with httpx.Client(timeout=2) as client:\n",
    "                client.post(f\"{self.base_url}/cleanup\")\n",
    "        except Exception:\n",
    "            pass  # Worker may already be gone\n",
    "        \n",
    "        # Terminate the subprocess\n",
    "        if self.process:\n",
    "            self.process.terminate()\n",
    "            try:\n",
    "                self.process.wait(timeout=2)\n",
    "            except subprocess.TimeoutExpired:\n",
    "                self.process.kill()\n",
    "            self.process = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serialization-header",
   "metadata": {},
   "source": [
    "### Input Serialization\n",
    "\n",
    "The proxy detects `FileBackedDTO` objects and serializes them to temp files before transmission. This enables zero-copy transfer of large data (audio, images) between processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serialization",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _maybe_serialize_input(\n",
    "    self,\n",
    "    obj: Any # Object to potentially serialize\n",
    ") -> Any: # Serialized form (path string or original object)\n",
    "    \"\"\"Convert FileBackedDTO objects to file paths for zero-copy transfer.\"\"\"\n",
    "    # Zero-Copy: Ask object to save itself\n",
    "    if isinstance(obj, FileBackedDTO):\n",
    "        return obj.to_temp_file()\n",
    "    # Paths: Convert to string\n",
    "    if isinstance(obj, Path):\n",
    "        return str(obj)\n",
    "    # Default: Pass through for JSON serialization\n",
    "    return obj\n",
    "\n",
    "def _prepare_payload(\n",
    "    self,\n",
    "    args: tuple, # Positional arguments\n",
    "    kwargs: dict # Keyword arguments\n",
    ") -> Dict[str, Any]: # JSON-serializable payload\n",
    "    \"\"\"Prepare arguments for HTTP transmission.\"\"\"\n",
    "    safe_args = [self._maybe_serialize_input(a) for a in args]\n",
    "    safe_kwargs = {k: self._maybe_serialize_input(v) for k, v in kwargs.items()}\n",
    "    return {\"args\": safe_args, \"kwargs\": safe_kwargs}\n",
    "\n",
    "RemotePluginProxy._maybe_serialize_input = _maybe_serialize_input\n",
    "RemotePluginProxy._prepare_payload = _prepare_payload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "async-header",
   "metadata": {},
   "source": [
    "### Asynchronous Interface\n",
    "\n",
    "These methods are `async` for use with FastHTML and other async frameworks. Use `execute_stream` for real-time streaming results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "async-methods",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "async def execute_async(\n",
    "    self,\n",
    "    *args,\n",
    "    **kwargs\n",
    ") -> Any: # Plugin result\n",
    "    \"\"\"Execute the plugin asynchronously.\"\"\"\n",
    "    payload = self._prepare_payload(args, kwargs)\n",
    "    async with httpx.AsyncClient(timeout=None) as client:\n",
    "        resp = await client.post(f\"{self.base_url}/execute\", json=payload)\n",
    "    \n",
    "    if resp.status_code != 200:\n",
    "        raise RuntimeError(f\"Execute failed: {resp.text}\")\n",
    "    return resp.json()\n",
    "\n",
    "def execute_stream_sync(self, *args, **kwargs) -> Generator[Any, None, None]:\n",
    "    \"\"\"Synchronous wrapper for streaming (blocking).\"\"\"\n",
    "    # This is tricky without \"httpx.stream\" in sync mode.\n",
    "    # For now, it's okay to leave it async-only if documented.\n",
    "    pass\n",
    "\n",
    "async def execute_stream(\n",
    "    self,\n",
    "    *args,\n",
    "    **kwargs\n",
    ") -> AsyncGenerator[Any, None]: # Yields parsed JSON chunks\n",
    "    \"\"\"Execute with streaming response (async generator).\"\"\"\n",
    "    payload = self._prepare_payload(args, kwargs)\n",
    "    async with httpx.AsyncClient(timeout=None) as client:\n",
    "        async with client.stream(\"POST\", f\"{self.base_url}/execute_stream\", json=payload) as resp:\n",
    "            async for line in resp.aiter_lines():\n",
    "                if line:\n",
    "                    yield json.loads(line)\n",
    "\n",
    "RemotePluginProxy.execute_async = execute_async\n",
    "RemotePluginProxy.execute_stream_sync = execute_stream_sync\n",
    "RemotePluginProxy.execute_stream = execute_stream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lifecycle-header",
   "metadata": {},
   "source": [
    "### Lifecycle Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lifecycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #| export\n",
    "def get_stats(self) -> Dict[str, Any]: # Process telemetry\n",
    "    \"\"\"Get worker process resource usage.\"\"\"\n",
    "    with httpx.Client() as client:\n",
    "        return client.get(f\"{self.base_url}/stats\").json()\n",
    "\n",
    "def is_alive(self) -> bool: # True if worker is responsive\n",
    "    \"\"\"Check if the worker process is still running and responsive.\"\"\"\n",
    "    if not self.process or self.process.poll() is not None:\n",
    "        return False\n",
    "    try:\n",
    "        with httpx.Client(timeout=2) as client:\n",
    "            resp = client.get(f\"{self.base_url}/health\")\n",
    "            return resp.status_code == 200\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "RemotePluginProxy.get_stats = get_stats\n",
    "RemotePluginProxy.is_alive = is_alive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "context-header",
   "metadata": {},
   "source": [
    "### Context Manager Support\n",
    "\n",
    "The proxy can be used as a context manager for automatic cleanup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "context-manager",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def __enter__(self):\n",
    "    \"\"\"Enter context manager.\"\"\"\n",
    "    return self\n",
    "\n",
    "def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "    \"\"\"Exit context manager and cleanup.\"\"\"\n",
    "    self.cleanup()\n",
    "    return False\n",
    "\n",
    "async def __aenter__(self):\n",
    "    \"\"\"Enter async context manager.\"\"\"\n",
    "    return self\n",
    "\n",
    "async def __aexit__(self, exc_type, exc_val, exc_tb):\n",
    "    \"\"\"Exit async context manager and cleanup.\"\"\"\n",
    "    self.cleanup()\n",
    "    return False\n",
    "\n",
    "RemotePluginProxy.__enter__ = __enter__\n",
    "RemotePluginProxy.__exit__ = __exit__\n",
    "RemotePluginProxy.__aenter__ = __aenter__\n",
    "RemotePluginProxy.__aexit__ = __aexit__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usage-header",
   "metadata": {},
   "source": [
    "## Usage Examples\n",
    "\n",
    "### Basic Usage (Sync)\n",
    "\n",
    "```python\n",
    "# Load manifest from JSON file\n",
    "with open(\"~/.cjm/plugins/whisper.json\") as f:\n",
    "    manifest = json.load(f)\n",
    "\n",
    "# Create proxy (starts worker subprocess)\n",
    "plugin = RemotePluginProxy(manifest)\n",
    "\n",
    "# Use like a local plugin\n",
    "plugin.initialize({\"model\": \"large-v3\"})\n",
    "result = plugin.execute(audio=\"/path/to/audio.wav\")\n",
    "\n",
    "# Clean up\n",
    "plugin.cleanup()\n",
    "```\n",
    "\n",
    "### With Context Manager\n",
    "\n",
    "```python\n",
    "with RemotePluginProxy(manifest) as plugin:\n",
    "    plugin.initialize({\"model\": \"large-v3\"})\n",
    "    result = plugin.execute(audio=\"/path/to/audio.wav\")\n",
    "# Worker automatically terminated\n",
    "```\n",
    "\n",
    "### Async with Streaming (FastHTML)\n",
    "\n",
    "```python\n",
    "async def transcribe_stream(audio_path: str):\n",
    "    async with RemotePluginProxy(manifest) as plugin:\n",
    "        await plugin.initialize({\"model\": \"large-v3\"})\n",
    "        async for chunk in plugin.execute_stream(audio=audio_path):\n",
    "            yield chunk  # Stream to client\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manifest-header",
   "metadata": {},
   "source": [
    "## Manifest Format\n",
    "\n",
    "The proxy expects a manifest dictionary with at minimum:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"name\": \"whisper-local\",\n",
    "    \"version\": \"1.0.0\",\n",
    "    \"python_path\": \"/home/user/anaconda3/envs/cjm-whisper/bin/python\",\n",
    "    \"module\": \"cjm_transcription_plugin_whisper.plugin\",\n",
    "    \"class\": \"WhisperLocalPlugin\",\n",
    "    \"env_vars\": {\n",
    "        \"CUDA_VISIBLE_DEVICES\": \"0\"\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nbdev-export",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
