[
  {
    "objectID": "core/proxy.html",
    "href": "core/proxy.html",
    "title": "Remote Plugin Proxy",
    "section": "",
    "text": "The RemotePluginProxy implements PluginInterface but forwards all calls over HTTP to a Worker process running in an isolated environment.\nKey responsibilities:",
    "crumbs": [
      "core",
      "Remote Plugin Proxy"
    ]
  },
  {
    "objectID": "core/proxy.html#remotepluginproxy",
    "href": "core/proxy.html#remotepluginproxy",
    "title": "Remote Plugin Proxy",
    "section": "RemotePluginProxy",
    "text": "RemotePluginProxy\n\nsource\n\nRemotePluginProxy\n\ndef RemotePluginProxy(\n    manifest:Dict, # Plugin manifest with python_path, module, class, etc.\n):\n\nProxy that forwards plugin calls to an isolated Worker subprocess.\n\n\nInput Serialization\nThe proxy detects FileBackedDTO objects and serializes them to temp files before transmission. This enables zero-copy transfer of large data (audio, images) between processes.\n\n\nAsynchronous Interface\nThese methods are async for use with FastHTML and other async frameworks. Use execute_stream for real-time streaming results.\n\nsource\n\n\nexecute_stream\n\ndef execute_stream(\n    args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n)-&gt;AsyncGenerator: # Yields parsed JSON chunks\n\nExecute with streaming response (async generator).\n\nsource\n\n\nexecute_stream_sync\n\ndef execute_stream_sync(\n    args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n)-&gt;Generator:\n\nSynchronous wrapper for streaming (blocking).\n\nsource\n\n\nexecute_async\n\nasync def execute_async(\n    args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n)-&gt;Any: # Plugin result\n\nExecute the plugin asynchronously.\n\n\nLifecycle Management\n\nsource\n\n\nis_alive\n\ndef is_alive(\n    \n)-&gt;bool: # True if worker is responsive\n\nCheck if the worker process is still running and responsive.\n\nsource\n\n\nget_stats\n\ndef get_stats(\n    \n)-&gt;Dict: # Process telemetry\n\nGet worker process resource usage.\n\n\nCancellation and Progress\nMethods for cancelling running executions and polling progress status.\n\nsource\n\n\nget_progress_async\n\nasync def get_progress_async(\n    \n)-&gt;Dict: # {progress: float, message: str}\n\nGet current execution progress asynchronously.\n\nsource\n\n\nget_progress\n\ndef get_progress(\n    \n)-&gt;Dict: # {progress: float, message: str}\n\nGet current execution progress from worker.\n\nsource\n\n\ncancel_async\n\nasync def cancel_async(\n    \n)-&gt;bool: # True if cancel request was sent\n\nRequest cancellation asynchronously.\n\nsource\n\n\ncancel\n\ndef cancel(\n    \n)-&gt;bool: # True if cancel request was sent\n\nRequest cancellation of running execution.\n\n\nContext Manager Support\nThe proxy can be used as a context manager for automatic cleanup.\n\nsource\n\n\naexit\n\nasync def __aexit__(\n    exc_type, exc_val, exc_tb\n):\n\nExit async context manager and cleanup.\n\nsource\n\n\naenter\n\nasync def __aenter__(\n    \n):\n\nEnter async context manager.\n\nsource\n\n\nexit\n\ndef __exit__(\n    exc_type, exc_val, exc_tb\n):\n\nExit context manager and cleanup.\n\nsource\n\n\nenter\n\ndef __enter__(\n    \n):\n\nEnter context manager.",
    "crumbs": [
      "core",
      "Remote Plugin Proxy"
    ]
  },
  {
    "objectID": "core/proxy.html#usage-examples",
    "href": "core/proxy.html#usage-examples",
    "title": "Remote Plugin Proxy",
    "section": "Usage Examples",
    "text": "Usage Examples\n\nBasic Usage (Sync)\n# Load manifest from JSON file\nwith open(\"~/.cjm/manifests/whisper.json\") as f:\n    manifest = json.load(f)\n\n# Create proxy (starts worker subprocess)\nplugin = RemotePluginProxy(manifest)\n\n# Use like a local plugin\nplugin.initialize({\"model\": \"large-v3\"})\nresult = plugin.execute(audio=\"/path/to/audio.wav\")\n\n# Clean up\nplugin.cleanup()\n\n\nWith Context Manager\nwith RemotePluginProxy(manifest) as plugin:\n    plugin.initialize({\"model\": \"large-v3\"})\n    result = plugin.execute(audio=\"/path/to/audio.wav\")\n# Worker automatically terminated\n\n\nAsync with Streaming (FastHTML)\nasync def transcribe_stream(audio_path: str):\n    async with RemotePluginProxy(manifest) as plugin:\n        await plugin.initialize({\"model\": \"large-v3\"})\n        async for chunk in plugin.execute_stream(audio=audio_path):\n            yield chunk  # Stream to client",
    "crumbs": [
      "core",
      "Remote Plugin Proxy"
    ]
  },
  {
    "objectID": "core/proxy.html#manifest-format",
    "href": "core/proxy.html#manifest-format",
    "title": "Remote Plugin Proxy",
    "section": "Manifest Format",
    "text": "Manifest Format\nThe proxy expects a manifest dictionary with at minimum:\n{\n    \"name\": \"whisper-local\",\n    \"version\": \"1.0.0\",\n    \"python_path\": \"/home/user/anaconda3/envs/cjm-whisper/bin/python\",\n    \"module\": \"cjm_transcription_plugin_whisper.plugin\",\n    \"class\": \"WhisperLocalPlugin\",\n    \"env_vars\": {\n        \"CUDA_VISIBLE_DEVICES\": \"0\"\n    }\n}",
    "crumbs": [
      "core",
      "Remote Plugin Proxy"
    ]
  },
  {
    "objectID": "core/manager.html",
    "href": "core/manager.html",
    "title": "Plugin Manager",
    "section": "",
    "text": "The PluginManager orchestrates the complete lifecycle of plugins in the process-isolated architecture:\n\nDiscovery: Finds plugin manifests in local (.cjm/manifests/) or global (~/.cjm/manifests/) directories\nLoading: Creates RemotePluginProxy instances that spawn isolated Worker subprocesses\nExecution: Forwards calls to Workers via HTTP, supports both sync and async\nLifecycle: Handles initialization, configuration updates, and cleanup\n\nPluginManager                           Worker Subprocesses\n┌─────────────────┐                    ┌─────────────────────┐\n│ discover_       │                    │ Conda Env: Whisper  │\n│   manifests()   │     HTTP/JSON      │   └─ WhisperPlugin  │\n│                 │◄──────────────────▶│                     │\n│ plugins:        │                    └─────────────────────┘\n│   whisper ──────┼──► RemoteProxy     ┌─────────────────────┐\n│   gemini ───────┼──► RemoteProxy ◄──▶│ Conda Env: Gemini   │\n│                 │                    │   └─ GeminiPlugin   │\n└─────────────────┘                    └─────────────────────┘\n\nsource\n\n\n\ndef PluginManager(\n    plugin_interface:Type=PluginInterface, # Base interface for type checking\n    search_paths:Optional=None, # Custom manifest search paths\n    scheduler:Optional=None, # Resource allocation policy\n):\n\nManages plugin discovery, loading, and lifecycle via process isolation.\nKey features:\n\nLocal-first discovery: Manifests in .cjm/manifests/ shadow global ones in ~/.cjm/manifests/\nProcess isolation: Each plugin runs in its own subprocess with a dedicated Python interpreter\nDual execution modes: execute_plugin() for sync, execute_plugin_async() for async\nAutomatic cleanup: unload_all() terminates all Worker processes",
    "crumbs": [
      "core",
      "Plugin Manager"
    ]
  },
  {
    "objectID": "core/manager.html#pluginmanager",
    "href": "core/manager.html#pluginmanager",
    "title": "Plugin Manager",
    "section": "",
    "text": "The PluginManager orchestrates the complete lifecycle of plugins in the process-isolated architecture:\n\nDiscovery: Finds plugin manifests in local (.cjm/manifests/) or global (~/.cjm/manifests/) directories\nLoading: Creates RemotePluginProxy instances that spawn isolated Worker subprocesses\nExecution: Forwards calls to Workers via HTTP, supports both sync and async\nLifecycle: Handles initialization, configuration updates, and cleanup\n\nPluginManager                           Worker Subprocesses\n┌─────────────────┐                    ┌─────────────────────┐\n│ discover_       │                    │ Conda Env: Whisper  │\n│   manifests()   │     HTTP/JSON      │   └─ WhisperPlugin  │\n│                 │◄──────────────────▶│                     │\n│ plugins:        │                    └─────────────────────┘\n│   whisper ──────┼──► RemoteProxy     ┌─────────────────────┐\n│   gemini ───────┼──► RemoteProxy ◄──▶│ Conda Env: Gemini   │\n│                 │                    │   └─ GeminiPlugin   │\n└─────────────────┘                    └─────────────────────┘\n\nsource\n\n\n\ndef PluginManager(\n    plugin_interface:Type=PluginInterface, # Base interface for type checking\n    search_paths:Optional=None, # Custom manifest search paths\n    scheduler:Optional=None, # Resource allocation policy\n):\n\nManages plugin discovery, loading, and lifecycle via process isolation.\nKey features:\n\nLocal-first discovery: Manifests in .cjm/manifests/ shadow global ones in ~/.cjm/manifests/\nProcess isolation: Each plugin runs in its own subprocess with a dedicated Python interpreter\nDual execution modes: execute_plugin() for sync, execute_plugin_async() for async\nAutomatic cleanup: unload_all() terminates all Worker processes",
    "crumbs": [
      "core",
      "Plugin Manager"
    ]
  },
  {
    "objectID": "core/manager.html#configuration-management",
    "href": "core/manager.html#configuration-management",
    "title": "Plugin Manager",
    "section": "Configuration Management",
    "text": "Configuration Management\nMethods for managing plugin configuration. These forward to the RemotePluginProxy which communicates with the Worker over HTTP.\n\nsource\n\nget_plugin_stats\n\ndef get_plugin_stats(\n    plugin_name:str, # Name of the plugin\n)-&gt;Optional: # Resource telemetry or None\n\nGet resource usage stats for a plugin’s Worker process.\n\nsource\n\n\nreload_plugin\n\ndef reload_plugin(\n    plugin_name:str, # Name of the plugin\n    config:Optional=None, # Optional new configuration\n)-&gt;bool: # True if successful\n\nReload a plugin by terminating and restarting its Worker.\n\nsource\n\n\nupdate_plugin_config\n\ndef update_plugin_config(\n    plugin_name:str, # Name of the plugin\n    config:Dict, # New configuration values\n)-&gt;bool: # True if successful\n\nUpdate a plugin’s configuration (hot-reload without restart).\n\nsource\n\n\nget_all_plugin_configs\n\ndef get_all_plugin_configs(\n    \n)-&gt;Dict: # Plugin name -&gt; config mapping\n\nGet current configuration for all loaded plugins.\n\nsource\n\n\nget_plugin_config_schema\n\ndef get_plugin_config_schema(\n    plugin_name:str, # Name of the plugin\n)-&gt;Optional: # JSON Schema or None\n\nGet the configuration JSON Schema for a plugin.\n\nsource\n\n\nget_plugin_config\n\ndef get_plugin_config(\n    plugin_name:str, # Name of the plugin\n)-&gt;Optional: # Current configuration or None\n\nGet the current configuration of a plugin.",
    "crumbs": [
      "core",
      "Plugin Manager"
    ]
  },
  {
    "objectID": "core/manager.html#streaming-execution",
    "href": "core/manager.html#streaming-execution",
    "title": "Plugin Manager",
    "section": "Streaming Execution",
    "text": "Streaming Execution\nAsync streaming support for real-time results (e.g., transcription word-by-word).\n\nsource\n\nexecute_plugin_stream\n\ndef execute_plugin_stream(\n    plugin_name:str, # Name of the plugin\n    args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n)-&gt;AsyncGenerator: # Async generator yielding results\n\nExecute a plugin with streaming response.",
    "crumbs": [
      "core",
      "Plugin Manager"
    ]
  },
  {
    "objectID": "core/manager.html#usage-examples",
    "href": "core/manager.html#usage-examples",
    "title": "Plugin Manager",
    "section": "Usage Examples",
    "text": "Usage Examples\n\nBasic Usage\nimport logging\nfrom cjm_plugin_system.core.manager import PluginManager\n\nlogging.basicConfig(level=logging.INFO)\n\n# Create manager\nmanager = PluginManager()\n\n# Discover and load all plugins from manifest directories\nresults = manager.load_all()\nprint(f\"Loaded: {results}\")\n\n# Execute a plugin\nresult = manager.execute_plugin(\"whisper-local\", audio=\"/path/to/audio.wav\")\n\n# Update configuration (hot-reload)\nmanager.update_plugin_config(\"whisper-local\", {\"model\": \"large-v3\"})\n\n# Clean up all workers\nmanager.unload_all()\n\n\nAsync Usage (FastHTML)\nasync def transcribe(audio_path: str):\n    manager = PluginManager()\n    manager.load_all()\n    \n    try:\n        result = await manager.execute_plugin_async(\"whisper-local\", audio=audio_path)\n        return result\n    finally:\n        manager.unload_all()\n\n# Streaming\nasync def transcribe_stream(audio_path: str):\n    manager = PluginManager()\n    manager.load_all()\n    \n    try:\n        async for chunk in manager.execute_plugin_stream(\"whisper-local\", audio=audio_path):\n            yield chunk\n    finally:\n        manager.unload_all()",
    "crumbs": [
      "core",
      "Plugin Manager"
    ]
  },
  {
    "objectID": "core/platform.html",
    "href": "core/platform.html",
    "title": "Platform Utilities",
    "section": "",
    "text": "This module provides cross-platform utilities to support Linux, macOS, and Windows:",
    "crumbs": [
      "core",
      "Platform Utilities"
    ]
  },
  {
    "objectID": "core/platform.html#platform-detection",
    "href": "core/platform.html#platform-detection",
    "title": "Platform Utilities",
    "section": "Platform Detection",
    "text": "Platform Detection\nFunctions to detect the current operating system and architecture.\n\nsource\n\nis_apple_silicon\n\ndef is_apple_silicon(\n    \n)-&gt;bool:\n\nCheck if running on Apple Silicon Mac (for MPS detection).\n\nsource\n\n\nis_linux\n\ndef is_linux(\n    \n)-&gt;bool:\n\nCheck if running on Linux.\n\nsource\n\n\nis_macos\n\ndef is_macos(\n    \n)-&gt;bool:\n\nCheck if running on macOS.\n\nsource\n\n\nis_windows\n\ndef is_windows(\n    \n)-&gt;bool:\n\nCheck if running on Windows.\n\n# Test detection functions\nprint(f\"is_windows(): {is_windows()}\")\nprint(f\"is_macos(): {is_macos()}\")\nprint(f\"is_linux(): {is_linux()}\")\nprint(f\"is_apple_silicon(): {is_apple_silicon()}\")\n\n# Exactly one of these should be True\nassert sum([is_windows(), is_macos(), is_linux()]) == 1\n\nis_windows(): False\nis_macos(): False\nis_linux(): True\nis_apple_silicon(): False\n\n\n\nsource\n\n\nget_current_platform\n\ndef get_current_platform(\n    \n)-&gt;str:\n\nGet current platform string for manifest filtering.\nReturns strings like ‘linux-x64’, ‘darwin-arm64’, ‘win-x64’.\n\n# Test platform string\ncurrent = get_current_platform()\nprint(f\"Current platform: {current}\")\n\n# Should be one of the expected formats\nvalid_prefixes = [\"linux-\", \"darwin-\", \"win-\"]\nassert any(current.startswith(p) for p in valid_prefixes)\n\nCurrent platform: linux-x64",
    "crumbs": [
      "core",
      "Platform Utilities"
    ]
  },
  {
    "objectID": "core/platform.html#path-utilities",
    "href": "core/platform.html#path-utilities",
    "title": "Platform Utilities",
    "section": "Path Utilities",
    "text": "Path Utilities\nFunctions for cross-platform path handling, particularly for conda environments.\n\nsource\n\nget_python_in_env\n\ndef get_python_in_env(\n    env_path:Path, # Path to conda environment root\n)-&gt;Path: # Path to Python executable\n\nGet the Python executable path for a conda environment.\nOn Windows: env_path/python.exe On Unix: env_path/bin/python\n\n# Test path generation\ntest_env = Path(\"/home/user/miniforge3/envs/test-env\")\npython_path = get_python_in_env(test_env)\nprint(f\"Python path: {python_path}\")\n\nif is_windows():\n    assert python_path.name == \"python.exe\"\nelse:\n    assert \"bin\" in python_path.parts\n    assert python_path.name == \"python\"\n\nPython path: /home/user/miniforge3/envs/test-env/bin/python",
    "crumbs": [
      "core",
      "Platform Utilities"
    ]
  },
  {
    "objectID": "core/platform.html#process-management",
    "href": "core/platform.html#process-management",
    "title": "Platform Utilities",
    "section": "Process Management",
    "text": "Process Management\nCross-platform utilities for subprocess creation and termination.\n\nsource\n\nget_popen_isolation_kwargs\n\ndef get_popen_isolation_kwargs(\n    \n)-&gt;Dict:\n\nReturn kwargs for process isolation in subprocess.Popen.\nOn Unix: Returns {‘start_new_session’: True} On Windows: Returns {‘creationflags’: CREATE_NEW_PROCESS_GROUP}\nUsage: process = subprocess.Popen(cmd, **get_popen_isolation_kwargs(), …)\n\n# Test isolation kwargs\nkwargs = get_popen_isolation_kwargs()\nprint(f\"Isolation kwargs: {kwargs}\")\n\nif is_windows():\n    assert \"creationflags\" in kwargs\nelse:\n    assert kwargs.get(\"start_new_session\") == True\n\nIsolation kwargs: {'start_new_session': True}\n\n\n\nsource\n\n\nterminate_process\n\ndef terminate_process(\n    process:Popen, # Process to terminate\n    timeout:float=2.0, # Seconds to wait before force kill\n)-&gt;None:\n\nTerminate a subprocess gracefully, with fallback to force kill.\nOn all platforms: 1. Calls process.terminate() (SIGTERM on Unix, TerminateProcess on Windows) 2. Waits for timeout seconds 3. If still running, calls process.kill() (SIGKILL on Unix, TerminateProcess on Windows)\n\nsource\n\n\nterminate_self\n\ndef terminate_self(\n    \n)-&gt;None:\n\nTerminate the current process (for worker suicide pact).\nOn Unix: Sends SIGTERM to self for graceful shutdown On Windows: Calls os._exit() since Windows lacks SIGTERM",
    "crumbs": [
      "core",
      "Platform Utilities"
    ]
  },
  {
    "objectID": "core/platform.html#shell-command-execution",
    "href": "core/platform.html#shell-command-execution",
    "title": "Platform Utilities",
    "section": "Shell Command Execution",
    "text": "Shell Command Execution\nCross-platform shell command execution without hardcoded shell paths.\n\nsource\n\nrun_shell_command\n\ndef run_shell_command(\n    cmd:str, # Shell command to execute\n    check:bool=True, # Whether to raise on non-zero exit\n    capture_output:bool=False, # Whether to capture stdout/stderr\n    kwargs:VAR_KEYWORD\n)-&gt;CompletedProcess: # Additional kwargs passed to subprocess.run\n\nRun a shell command cross-platform.\nUnlike using shell=True with executable=‘/bin/bash’, this function uses the platform’s default shell: - Linux/macOS: /bin/sh (or $SHELL) - Windows: cmd.exe\n\nsource\n\n\nconda_env_exists\n\ndef conda_env_exists(\n    env_name:str, # Name of the conda environment\n    conda_cmd:str='conda', # Conda command (conda, mamba, micromamba)\n)-&gt;bool:\n\nCheck if a conda environment exists (cross-platform).\nUses ‘conda env list –json’ instead of piping to grep, which doesn’t work on Windows.\n\n# Test shell command (simple echo)\nif is_windows():\n    result = run_shell_command(\"echo hello\", capture_output=True)\nelse:\n    result = run_shell_command(\"echo hello\", capture_output=True)\n\nprint(f\"Return code: {result.returncode}\")\nprint(f\"Output: {result.stdout}\")\nassert result.returncode == 0\n\nRunning: echo hello\nReturn code: 0\nOutput: b'hello\\n'\n\n\n\n# Test conda_env_exists (will return False for non-existent env)\nexists = conda_env_exists(\"this-env-should-not-exist-12345\")\nprint(f\"Non-existent env exists: {exists}\")\nassert exists == False\n\n# Test with base env \"miniforge3\" (should exist if miniforge3 is installed)\nbase_exists = conda_env_exists(\"miniforge3\")\nprint(f\"Base env exists: {base_exists}\")\n\nNon-existent env exists: False\nBase env exists: True",
    "crumbs": [
      "core",
      "Platform Utilities"
    ]
  },
  {
    "objectID": "core/platform.html#condamicromamba-management",
    "href": "core/platform.html#condamicromamba-management",
    "title": "Platform Utilities",
    "section": "Conda/Micromamba Management",
    "text": "Conda/Micromamba Management\nFunctions for managing conda and micromamba runtimes, including downloading micromamba binaries and building commands with proper prefix handling for project-local mode.\n\nsource\n\nget_micromamba_download_url\n\ndef get_micromamba_download_url(\n    platform_str:Optional=None, # Platform string (e.g., 'linux-x64'), uses current if None\n)-&gt;str: # Download URL for micromamba binary\n\nGet the micromamba download URL for the specified or current platform.\n\nsource\n\n\ndownload_micromamba\n\ndef download_micromamba(\n    dest_path:Path, # Destination path for the micromamba binary\n    platform_str:Optional=None, # Platform string, uses current if None\n    show_progress:bool=True, # Whether to print progress messages\n)-&gt;bool: # True if download succeeded\n\nDownload and extract micromamba binary to the specified path.\n\n# Test micromamba URL functions\ncurrent_platform = get_current_platform()\nurl = get_micromamba_download_url()\nprint(f\"Platform: {current_platform}\")\nprint(f\"Download URL: {url}\")\n\n# Verify all platforms have URLs\nfor plat in [\"linux-x64\", \"linux-arm64\", \"darwin-x64\", \"darwin-arm64\", \"win-x64\"]:\n    assert plat in MICROMAMBA_URLS, f\"Missing URL for {plat}\"\n    print(f\"  {plat}: {MICROMAMBA_URLS[plat]}\")\n\nPlatform: linux-x64\nDownload URL: https://micro.mamba.pm/api/micromamba/linux-64/latest\n  linux-x64: https://micro.mamba.pm/api/micromamba/linux-64/latest\n  linux-arm64: https://micro.mamba.pm/api/micromamba/linux-aarch64/latest\n  darwin-x64: https://micro.mamba.pm/api/micromamba/osx-64/latest\n  darwin-arm64: https://micro.mamba.pm/api/micromamba/osx-arm64/latest\n  win-x64: https://micro.mamba.pm/api/micromamba/win-64/latest\n\n\n\n\nConda Command Building\nFunctions to build conda/mamba/micromamba commands with proper prefix handling for project-local mode.\n\nsource\n\n\nget_conda_command\n\ndef get_conda_command(\n    config:CJMConfig, # Configuration object with runtime settings\n)-&gt;List: # Base command with prefix args if needed\n\nGet the conda/mamba/micromamba base command with prefix args for local mode.\n\nsource\n\n\nbuild_conda_command\n\ndef build_conda_command(\n    config:CJMConfig, # Configuration object with runtime settings\n    args:str, # Additional command arguments\n)-&gt;List: # Complete command ready for subprocess\n\nBuild a complete conda/mamba/micromamba command.\n\nsource\n\n\nget_micromamba_binary_path\n\ndef get_micromamba_binary_path(\n    config:CJMConfig, # Configuration object with runtime settings\n)-&gt;Optional: # Path to micromamba binary or None\n\nGet the configured micromamba binary path for the current platform.\n\nsource\n\n\nensure_runtime_available\n\ndef ensure_runtime_available(\n    config:CJMConfig, # Configuration object with runtime settings\n)-&gt;bool: # True if runtime is available\n\nCheck if the configured conda/micromamba runtime is available.\n\n# Test conda command building\nfrom cjm_plugin_system.core.config import CJMConfig, RuntimeConfig, CondaType, RuntimeMode\n\n# Test with default conda\ndefault_config = CJMConfig()\ncmd = get_conda_command(default_config)\nprint(f\"Default (conda): {cmd}\")\nassert cmd == [\"conda\"]\n\n# Test with miniforge/mamba\nmamba_config = CJMConfig(runtime=RuntimeConfig(conda_type=CondaType.MINIFORGE))\ncmd = get_conda_command(mamba_config)\nprint(f\"Miniforge (mamba): {cmd}\")\nassert cmd == [\"mamba\"]\n\n# Test with micromamba system mode\nmicromamba_system = CJMConfig(runtime=RuntimeConfig(conda_type=CondaType.MICROMAMBA))\ncmd = get_conda_command(micromamba_system)\nprint(f\"Micromamba (system): {cmd}\")\nassert cmd == [\"micromamba\"]\n\n# Test with micromamba local mode\nmicromamba_local = CJMConfig(\n    runtime=RuntimeConfig(\n        conda_type=CondaType.MICROMAMBA,\n        mode=RuntimeMode.LOCAL,\n        prefix=Path(\"./runtime\")\n    )\n)\ncmd = get_conda_command(micromamba_local)\nprint(f\"Micromamba (local): {cmd}\")\n# Path(\"./runtime\") normalizes to \"runtime\" when converted to str\nassert cmd == [\"micromamba\", \"-r\", \"runtime\"]\n\n# Test build_conda_command\nfull_cmd = build_conda_command(micromamba_local, \"create\", \"-n\", \"test-env\", \"-y\")\nprint(f\"Full command: {full_cmd}\")\nassert full_cmd == [\"micromamba\", \"-r\", \"runtime\", \"create\", \"-n\", \"test-env\", \"-y\"]\n\nDefault (conda): ['conda']\nMiniforge (mamba): ['mamba']\nMicromamba (system): ['micromamba']\nMicromamba (local): ['micromamba', '-r', 'runtime']\nFull command: ['micromamba', '-r', 'runtime', 'create', '-n', 'test-env', '-y']",
    "crumbs": [
      "core",
      "Platform Utilities"
    ]
  },
  {
    "objectID": "core/platform.html#summary",
    "href": "core/platform.html#summary",
    "title": "Platform Utilities",
    "section": "Summary",
    "text": "Summary\nThis module provides the following cross-platform utilities:\n\nDetection\n\nis_windows(), is_macos(), is_linux() - OS detection\nis_apple_silicon() - Apple Silicon detection for MPS\nget_current_platform() - Platform string like “linux-x64”\n\n\n\nPaths\n\nget_python_in_env(env_path) - Python executable path in conda env\n\n\n\nProcess Management\n\nget_popen_isolation_kwargs() - Kwargs for subprocess isolation\nterminate_process(process, timeout) - Graceful process termination\nterminate_self() - Self-termination for suicide pact\n\n\n\nShell Commands\n\nrun_shell_command(cmd, ...) - Cross-platform shell execution\nconda_env_exists(env_name) - Check if conda env exists\n\n\n\nConda/Micromamba Management\n\nMICROMAMBA_URLS - Download URLs for micromamba binaries by platform\nget_micromamba_download_url(platform) - Get download URL for current/specified platform\ndownload_micromamba(dest_path) - Download and extract micromamba binary\nget_conda_command(config) - Get base command with prefix args for local mode\nbuild_conda_command(config, *args) - Build complete conda/micromamba command\nget_micromamba_binary_path(config) - Get configured binary path for current platform\nensure_runtime_available(config) - Check if runtime is available",
    "crumbs": [
      "core",
      "Platform Utilities"
    ]
  },
  {
    "objectID": "core/queue.html",
    "href": "core/queue.html",
    "title": "Job Queue",
    "section": "",
    "text": "The JobQueue provides a resource-aware job queue for plugin execution:\nKey features:",
    "crumbs": [
      "core",
      "Job Queue"
    ]
  },
  {
    "objectID": "core/queue.html#jobstatus",
    "href": "core/queue.html#jobstatus",
    "title": "Job Queue",
    "section": "JobStatus",
    "text": "JobStatus\nEnumeration of possible job states.\n\nsource\n\nJobStatus\n\ndef JobStatus(\n    args:VAR_POSITIONAL, kwds:VAR_KEYWORD\n):\n\nStatus of a job in the queue.",
    "crumbs": [
      "core",
      "Job Queue"
    ]
  },
  {
    "objectID": "core/queue.html#job",
    "href": "core/queue.html#job",
    "title": "Job Queue",
    "section": "Job",
    "text": "Job\nDataclass representing a queued plugin execution.\n\nsource\n\nJob\n\ndef Job(\n    id:str, plugin_name:str, args:Tuple, kwargs:Dict, status:JobStatus=&lt;JobStatus.pending: 'pending'&gt;,\n    priority:int=0, created_at:float=&lt;factory&gt;, started_at:Optional=None, completed_at:Optional=None,\n    result:Any=None, error:Optional=None, progress:float=0.0, status_message:str=''\n)-&gt;None:\n\nA queued plugin execution request.",
    "crumbs": [
      "core",
      "Job Queue"
    ]
  },
  {
    "objectID": "core/queue.html#jobqueue",
    "href": "core/queue.html#jobqueue",
    "title": "Job Queue",
    "section": "JobQueue",
    "text": "JobQueue\nMain queue class that manages job submission, execution, and lifecycle.\n\nsource\n\nJobQueue\n\ndef JobQueue(\n    manager:PluginManager, # Plugin manager instance\n    max_history:int=100, # Max completed jobs to retain\n    cancel_timeout:float=3.0, # Seconds to wait for cooperative cancel\n    progress_poll_interval:float=1.0, # Seconds between progress polls\n):\n\nResource-aware job queue for sequential plugin execution.\n\n\nJob Submission\n\nsource\n\n\nsubmit\n\nasync def submit(\n    plugin_name:str, # Target plugin\n    args:VAR_POSITIONAL, priority:int=0, # Higher = more urgent\n    kwargs:VAR_KEYWORD\n)-&gt;str: # Returns job_id\n\nSubmit a job to the queue.\n\n\nJob Control\n\nsource\n\n\nreorder\n\ndef reorder(\n    job_id:str, # Job to move\n    new_priority:int, # New priority value\n)-&gt;bool: # True if reordered\n\nChange the priority of a pending job.\n\nsource\n\n\ncancel\n\nasync def cancel(\n    job_id:str, # Job to cancel\n)-&gt;bool: # True if cancelled\n\nCancel a pending or running job.\n\n\nObservation\n\nsource\n\n\nget_job_logs\n\ndef get_job_logs(\n    job_id:str, # Job to get logs for\n    lines:int=100, # Max lines to return\n)-&gt;str: # Log content\n\nGet logs for a job from the plugin’s log file.\n\nsource\n\n\nget_state\n\ndef get_state(\n    \n)-&gt;Dict: # Queue state for UI\n\nGet the current queue state.\n\nsource\n\n\nwait_for_job\n\nasync def wait_for_job(\n    job_id:str, # Job to wait for\n    timeout:Optional=None, # Max seconds to wait\n)-&gt;Job: # Completed/failed/cancelled job\n\nWait for a job to complete.\n\nsource\n\n\nget_job\n\ndef get_job(\n    job_id:str, # Job to retrieve\n)-&gt;Optional: # Job or None\n\nGet a job by ID.\n\n\nLifecycle\n\nsource\n\n\nstop\n\nasync def stop(\n    \n)-&gt;None:\n\nStop the queue processor gracefully.\n\nsource\n\n\nstart\n\nasync def start(\n    \n)-&gt;None:\n\nStart the queue processor.\n\n\nInternal Methods",
    "crumbs": [
      "core",
      "Job Queue"
    ]
  },
  {
    "objectID": "core/queue.html#usage-example",
    "href": "core/queue.html#usage-example",
    "title": "Job Queue",
    "section": "Usage Example",
    "text": "Usage Example\nfrom cjm_plugin_system.core.manager import PluginManager\nfrom cjm_plugin_system.core.queue import JobQueue, JobStatus\nfrom cjm_plugin_system.core.scheduling import QueueScheduler\n\n# Setup\nmanager = PluginManager(scheduler=QueueScheduler())\nmanager.discover_manifests()\nmanager.load_plugin(manager.get_discovered_meta(\"sys-mon\"))\nmanager.register_system_monitor(\"sys-mon\")\n\n# Create queue\nqueue = JobQueue(manager)\nawait queue.start()\n\n# Submit jobs\njob1_id = await queue.submit(\"whisper\", audio=\"/path/to/audio1.mp3\")\njob2_id = await queue.submit(\"gemini-vision\", image=\"/path/to/image.png\")\njob3_id = await queue.submit(\"whisper\", audio=\"/path/to/audio2.mp3\", priority=10)\n\n# Monitor queue state\nstate = queue.get_state()\nprint(f\"Running: {state['running']}\")\nprint(f\"Pending: {len(state['pending'])} jobs\")\n\n# Cancel a job\nawait queue.cancel(job2_id)\n\n# Wait for a job to complete\njob1 = await queue.wait_for_job(job1_id)\nif job1.status == JobStatus.completed:\n    print(job1.result)\n\n# Cleanup\nawait queue.stop()\nmanager.unload_all()",
    "crumbs": [
      "core",
      "Job Queue"
    ]
  },
  {
    "objectID": "core/config.html",
    "href": "core/config.html",
    "title": "Configuration",
    "section": "",
    "text": "Enums for runtime mode and conda implementation type.\n\nsource\n\n\n\ndef CondaType(\n    args:VAR_POSITIONAL, kwds:VAR_KEYWORD\n):\n\nType of conda implementation to use.\n\nsource\n\n\n\n\ndef RuntimeMode(\n    args:VAR_POSITIONAL, kwds:VAR_KEYWORD\n):\n\nRuntime mode for the plugin system.",
    "crumbs": [
      "core",
      "Configuration"
    ]
  },
  {
    "objectID": "core/config.html#configuration-enums",
    "href": "core/config.html#configuration-enums",
    "title": "Configuration",
    "section": "",
    "text": "Enums for runtime mode and conda implementation type.\n\nsource\n\n\n\ndef CondaType(\n    args:VAR_POSITIONAL, kwds:VAR_KEYWORD\n):\n\nType of conda implementation to use.\n\nsource\n\n\n\n\ndef RuntimeMode(\n    args:VAR_POSITIONAL, kwds:VAR_KEYWORD\n):\n\nRuntime mode for the plugin system.",
    "crumbs": [
      "core",
      "Configuration"
    ]
  },
  {
    "objectID": "core/config.html#configuration-dataclasses",
    "href": "core/config.html#configuration-dataclasses",
    "title": "Configuration",
    "section": "Configuration Dataclasses",
    "text": "Configuration Dataclasses\nRuntimeConfig holds conda/environment settings. CJMConfig is the main configuration container with paths and runtime settings.\n\nsource\n\nRuntimeConfig\n\ndef RuntimeConfig(\n    mode:RuntimeMode=&lt;RuntimeMode.SYSTEM: 'system'&gt;, conda_type:CondaType=&lt;CondaType.CONDA: 'conda'&gt;,\n    prefix:Optional=None, binaries:Dict=&lt;factory&gt;\n)-&gt;None:\n\nRuntime environment configuration.\n\nsource\n\n\nCJMConfig\n\ndef CJMConfig(\n    runtime:RuntimeConfig=&lt;factory&gt;, data_dir:Path=&lt;factory&gt;, plugins_config:Path=&lt;factory&gt;,\n    models_dir:Optional=None\n)-&gt;None:\n\nMain configuration for cjm-plugin-system.",
    "crumbs": [
      "core",
      "Configuration"
    ]
  },
  {
    "objectID": "core/config.html#configuration-loading",
    "href": "core/config.html#configuration-loading",
    "title": "Configuration",
    "section": "Configuration Loading",
    "text": "Configuration Loading\nFunctions for loading configuration with layered resolution:\n\nCLI flags (highest priority)\nEnvironment variables\ncjm.yaml file\nDefaults (backward compatible)\n\n\nsource\n\nload_config\n\ndef load_config(\n    config_path:Optional=None, # CLI --cjm-config\n    data_dir:Optional=None, # CLI --data-dir\n    conda_prefix:Optional=None, # CLI --conda-prefix\n    conda_type:Optional=None, # CLI --conda-type\n)-&gt;CJMConfig: # Resolved configuration\n\nLoad config with layered resolution (CLI &gt; env vars &gt; yaml &gt; defaults).",
    "crumbs": [
      "core",
      "Configuration"
    ]
  },
  {
    "objectID": "core/config.html#global-config-access",
    "href": "core/config.html#global-config-access",
    "title": "Configuration",
    "section": "Global Config Access",
    "text": "Global Config Access\nFunctions for getting and setting the module-level configuration singleton.\n\nsource\n\nreset_config\n\ndef reset_config(\n    \n)-&gt;None:\n\nReset to unloaded state (for testing).\n\nsource\n\n\nset_config\n\ndef set_config(\n    config:CJMConfig, # Configuration to set as current\n)-&gt;None:\n\nSet current config (called by CLI callback).\n\nsource\n\n\nget_config\n\ndef get_config(\n    \n)-&gt;CJMConfig: # Current configuration\n\nGet current config (loads defaults if not set).",
    "crumbs": [
      "core",
      "Configuration"
    ]
  },
  {
    "objectID": "core/config.html#examples",
    "href": "core/config.html#examples",
    "title": "Configuration",
    "section": "Examples",
    "text": "Examples\n\n# Test default configuration\nreset_config()\ncfg = get_config()\n\nprint(\"Default configuration:\")\nprint(f\"  data_dir: {cfg.data_dir}\")\nprint(f\"  manifests_dir: {cfg.manifests_dir}\")\nprint(f\"  plugin_data_dir: {cfg.plugin_data_dir}\")\nprint(f\"  logs_dir: {cfg.logs_dir}\")\nprint(f\"  plugins_config: {cfg.plugins_config}\")\nprint(f\"  runtime.mode: {cfg.runtime.mode}\")\nprint(f\"  runtime.conda_type: {cfg.runtime.conda_type}\")\n\nDefault configuration:\n  data_dir: /home/innom-dt/.cjm\n  manifests_dir: /home/innom-dt/.cjm/manifests\n  plugin_data_dir: /home/innom-dt/.cjm/data\n  logs_dir: /home/innom-dt/.cjm/logs\n  plugins_config: plugins.yaml\n  runtime.mode: RuntimeMode.SYSTEM\n  runtime.conda_type: CondaType.CONDA\n\n\n\n# Test CLI override\nreset_config()\ncfg = load_config(data_dir=Path(\"/custom/path\"))\n\nprint(\"With CLI override:\")\nprint(f\"  data_dir: {cfg.data_dir}\")\nprint(f\"  manifests_dir: {cfg.manifests_dir}\")\nprint(f\"  plugin_data_dir: {cfg.plugin_data_dir}\")\n\nWith CLI override:\n  data_dir: /custom/path\n  manifests_dir: /custom/path/manifests\n  plugin_data_dir: /custom/path/data\n\n\n\n# Test dataclass creation\nruntime = RuntimeConfig(\n    mode=RuntimeMode.LOCAL,\n    conda_type=CondaType.MINIFORGE,\n    prefix=Path(\"./runtime\")\n)\n\nconfig = CJMConfig(\n    runtime=runtime,\n    data_dir=Path(\"./.cjm\")\n)\n\nprint(\"Custom configuration:\")\nprint(f\"  runtime.mode: {config.runtime.mode}\")\nprint(f\"  runtime.conda_type: {config.runtime.conda_type}\")\nprint(f\"  runtime.prefix: {config.runtime.prefix}\")\nprint(f\"  data_dir: {config.data_dir}\")\n\nCustom configuration:\n  runtime.mode: RuntimeMode.LOCAL\n  runtime.conda_type: CondaType.MINIFORGE\n  runtime.prefix: runtime\n  data_dir: .cjm\n\n\n\n# Test conda_binary_path property\nruntime_with_binaries = RuntimeConfig(\n    conda_type=CondaType.MICROMAMBA,\n    mode=RuntimeMode.LOCAL,\n    prefix=Path(\"./runtime\"),\n    binaries={\"linux-x64\": Path(\"./runtime/bin/micromamba\")}\n)\n\nconfig_with_binaries = CJMConfig(runtime=runtime_with_binaries)\nprint(f\"conda_binary_path (from binaries): {config_with_binaries.conda_binary_path}\")\n\n# Test default path generation when binaries not specified\nruntime_no_binaries = RuntimeConfig(\n    conda_type=CondaType.MICROMAMBA,\n    mode=RuntimeMode.LOCAL,\n    prefix=Path(\"./runtime\")\n)\n\nconfig_no_binaries = CJMConfig(runtime=runtime_no_binaries)\nprint(f\"conda_binary_path (default): {config_no_binaries.conda_binary_path}\")\n\nconda_binary_path (from binaries): runtime/bin/micromamba\nconda_binary_path (default): runtime/bin/micromamba\n\n\n\n# Cleanup\nreset_config()",
    "crumbs": [
      "core",
      "Configuration"
    ]
  },
  {
    "objectID": "utils/hashing.html",
    "href": "utils/hashing.html",
    "title": "Content Hashing Utilities",
    "section": "",
    "text": "Computes a cryptographic hash of byte content, returning a self-describing string in \"algo:hexdigest\" format. This format embeds the algorithm name, making hashes forward-compatible if the algorithm changes.\n\nsource\n\n\n\ndef hash_bytes(\n    content:bytes, # Byte content to hash\n    algo:str='sha256', # Hash algorithm name (e.g., \"sha256\", \"sha3_256\")\n)-&gt;str: # Hash string in \"algo:hexdigest\" format\n\nCompute a hash of byte content.\n\nresult = hash_bytes(b\"hello world\")\nprint(f\"hash_bytes result: {result}\")\n\n# Check format\nalgo, digest = result.split(\":\", 1)\nassert algo == \"sha256\"\nassert len(digest) == 64  # SHA-256 produces 64 hex chars\n\n# Deterministic\nassert hash_bytes(b\"hello world\") == hash_bytes(b\"hello world\")\n\n# Different content produces different hash\nassert hash_bytes(b\"hello world\") != hash_bytes(b\"hello World\")\n\nprint(\"hash_bytes tests passed\")\n\nhash_bytes result: sha256:b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9\nhash_bytes tests passed\n\n\n\n# Custom algorithm\nsha512_result = hash_bytes(b\"test\", algo=\"sha512\")\nprint(f\"SHA-512 result: {sha512_result[:30]}...\")\nassert sha512_result.startswith(\"sha512:\")\nassert len(sha512_result.split(\":\")[1]) == 128  # SHA-512 produces 128 hex chars\n\nprint(\"Custom algorithm test passed\")\n\nSHA-512 result: sha512:ee26b0dd4af7e749aa1a8ee...\nCustom algorithm test passed",
    "crumbs": [
      "utils",
      "Content Hashing Utilities"
    ]
  },
  {
    "objectID": "utils/hashing.html#hash_bytes",
    "href": "utils/hashing.html#hash_bytes",
    "title": "Content Hashing Utilities",
    "section": "",
    "text": "Computes a cryptographic hash of byte content, returning a self-describing string in \"algo:hexdigest\" format. This format embeds the algorithm name, making hashes forward-compatible if the algorithm changes.\n\nsource\n\n\n\ndef hash_bytes(\n    content:bytes, # Byte content to hash\n    algo:str='sha256', # Hash algorithm name (e.g., \"sha256\", \"sha3_256\")\n)-&gt;str: # Hash string in \"algo:hexdigest\" format\n\nCompute a hash of byte content.\n\nresult = hash_bytes(b\"hello world\")\nprint(f\"hash_bytes result: {result}\")\n\n# Check format\nalgo, digest = result.split(\":\", 1)\nassert algo == \"sha256\"\nassert len(digest) == 64  # SHA-256 produces 64 hex chars\n\n# Deterministic\nassert hash_bytes(b\"hello world\") == hash_bytes(b\"hello world\")\n\n# Different content produces different hash\nassert hash_bytes(b\"hello world\") != hash_bytes(b\"hello World\")\n\nprint(\"hash_bytes tests passed\")\n\nhash_bytes result: sha256:b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9\nhash_bytes tests passed\n\n\n\n# Custom algorithm\nsha512_result = hash_bytes(b\"test\", algo=\"sha512\")\nprint(f\"SHA-512 result: {sha512_result[:30]}...\")\nassert sha512_result.startswith(\"sha512:\")\nassert len(sha512_result.split(\":\")[1]) == 128  # SHA-512 produces 128 hex chars\n\nprint(\"Custom algorithm test passed\")\n\nSHA-512 result: sha512:ee26b0dd4af7e749aa1a8ee...\nCustom algorithm test passed",
    "crumbs": [
      "utils",
      "Content Hashing Utilities"
    ]
  },
  {
    "objectID": "utils/hashing.html#hash_file",
    "href": "utils/hashing.html#hash_file",
    "title": "Content Hashing Utilities",
    "section": "hash_file",
    "text": "hash_file\nStream-hashes a file without loading it entirely into memory. Uses chunked reads suitable for large files (audio, video, etc.).\n\nsource\n\nhash_file\n\ndef hash_file(\n    path:Union, # Path to file to hash\n    algo:str='sha256', # Hash algorithm name\n    chunk_size:int=8192, # Read chunk size in bytes\n)-&gt;str: # Hash string in \"algo:hexdigest\" format\n\nStream-hash a file without loading it entirely into memory.\n\nimport tempfile\nimport os\n\n# Create a temp file with known content\nwith tempfile.NamedTemporaryFile(delete=False, mode='wb') as tmp:\n    tmp.write(b\"hello world\")\n    tmp_path = tmp.name\n\n# Hash the file\nfile_hash = hash_file(tmp_path)\nprint(f\"hash_file result: {file_hash}\")\n\n# Should match hash_bytes of the same content\nassert file_hash == hash_bytes(b\"hello world\")\n\n# Test with Path object\nassert hash_file(Path(tmp_path)) == file_hash\n\n# Cleanup\nos.unlink(tmp_path)\nprint(\"hash_file tests passed\")\n\nhash_file result: sha256:b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9\nhash_file tests passed",
    "crumbs": [
      "utils",
      "Content Hashing Utilities"
    ]
  },
  {
    "objectID": "utils/hashing.html#verify_hash",
    "href": "utils/hashing.html#verify_hash",
    "title": "Content Hashing Utilities",
    "section": "verify_hash",
    "text": "verify_hash\nVerifies byte content against an expected hash string. Automatically extracts the algorithm from the \"algo:hexdigest\" format.\n\nsource\n\nverify_hash\n\ndef verify_hash(\n    content:bytes, # Content to verify\n    expected:str, # Expected hash in \"algo:hexdigest\" format\n)-&gt;bool: # True if content matches expected hash\n\nVerify content against an expected hash string.\n\noriginal = b\"hello world\"\nh = hash_bytes(original)\n\n# Matching content\nassert verify_hash(original, h) == True\n\n# Modified content\nassert verify_hash(b\"hello World\", h) == False\n\n# Works with different algorithms\nh_sha512 = hash_bytes(original, algo=\"sha512\")\nassert verify_hash(original, h_sha512) == True\nassert verify_hash(b\"tampered\", h_sha512) == False\n\nprint(\"verify_hash tests passed\")\n\nverify_hash tests passed",
    "crumbs": [
      "utils",
      "Content Hashing Utilities"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "cjm-plugin-system",
    "section": "",
    "text": "pip install cjm_plugin_system",
    "crumbs": [
      "cjm-plugin-system"
    ]
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "cjm-plugin-system",
    "section": "",
    "text": "pip install cjm_plugin_system",
    "crumbs": [
      "cjm-plugin-system"
    ]
  },
  {
    "objectID": "index.html#project-structure",
    "href": "index.html#project-structure",
    "title": "cjm-plugin-system",
    "section": "Project Structure",
    "text": "Project Structure\nnbs/\n├── core/ (9)\n│   ├── config.ipynb      # Project-level configuration for paths, runtime settings, and environment management\n│   ├── interface.ipynb   # Abstract base class defining the generic plugin interface\n│   ├── manager.ipynb     # Plugin discovery, loading, and lifecycle management system\n│   ├── metadata.ipynb    # Data structures for plugin metadata\n│   ├── platform.ipynb    # Cross-platform utilities for process management, path handling, and system detection\n│   ├── proxy.ipynb       # Bridge between Host application and isolated Worker processes\n│   ├── queue.ipynb       # Resource-aware job queue for sequential plugin execution with cancellation support\n│   ├── scheduling.ipynb  # Resource scheduling policies for plugin execution\n│   └── worker.ipynb      # FastAPI server that runs inside isolated plugin environments\n├── utils/ (2)\n│   ├── hashing.ipynb     # Shared cryptographic hashing primitives for content integrity verification\n│   └── validation.ipynb  # Validation helpers for plugin configuration dataclasses\n└── cli.ipynb  # CLI tool for declarative plugin management\nTotal: 12 notebooks across 2 directories",
    "crumbs": [
      "cjm-plugin-system"
    ]
  },
  {
    "objectID": "index.html#module-dependencies",
    "href": "index.html#module-dependencies",
    "title": "cjm-plugin-system",
    "section": "Module Dependencies",
    "text": "Module Dependencies\ngraph LR\n    cli[cli&lt;br/&gt;cli]\n    core_config[core.config&lt;br/&gt;Configuration]\n    core_interface[core.interface&lt;br/&gt;Plugin Interface]\n    core_manager[core.manager&lt;br/&gt;Plugin Manager]\n    core_metadata[core.metadata&lt;br/&gt;Plugin Metadata]\n    core_platform[core.platform&lt;br/&gt;Platform Utilities]\n    core_proxy[core.proxy&lt;br/&gt;Remote Plugin Proxy]\n    core_queue[core.queue&lt;br/&gt;Job Queue]\n    core_scheduling[core.scheduling&lt;br/&gt;Scheduling]\n    core_worker[core.worker&lt;br/&gt;Universal Worker]\n    utils_hashing[utils.hashing&lt;br/&gt;Content Hashing Utilities]\n    utils_validation[utils.validation&lt;br/&gt;Configuration Validation]\n\n    cli --&gt; core_platform\n    cli --&gt; core_config\n    core_manager --&gt; core_interface\n    core_manager --&gt; core_scheduling\n    core_manager --&gt; core_metadata\n    core_manager --&gt; core_proxy\n    core_manager --&gt; core_config\n    core_platform --&gt; core_config\n    core_proxy --&gt; core_platform\n    core_proxy --&gt; core_interface\n    core_proxy --&gt; core_config\n    core_queue --&gt; core_manager\n    core_scheduling --&gt; core_metadata\n    core_worker --&gt; core_platform\n14 cross-module dependencies detected",
    "crumbs": [
      "cjm-plugin-system"
    ]
  },
  {
    "objectID": "index.html#cli-reference",
    "href": "index.html#cli-reference",
    "title": "cjm-plugin-system",
    "section": "CLI Reference",
    "text": "CLI Reference\n\ncjm-ctl Command\n                                                                                                          \n Usage: cjm-ctl [OPTIONS] COMMAND [ARGS]...                                                               \n                                                                                                          \n CJM Plugin System CLI                                                                                    \n                                                                                                          \n╭─ Options ──────────────────────────────────────────────────────────────────────────────────────────────╮\n│ --cjm-config                PATH  Path to cjm.yaml configuration file                                  │\n│ --data-dir                  PATH  Override data directory (manifests, logs)                            │\n│ --conda-prefix              PATH  Override conda/mamba prefix path                                     │\n│ --conda-type                TEXT  Conda implementation: micromamba, miniforge, or conda                │\n│ --install-completion              Install completion for the current shell.                            │\n│ --show-completion                 Show completion for the current shell, to copy it or customize the   │\n│                                   installation.                                                        │\n│ --help                            Show this message and exit.                                          │\n╰────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n╭─ Commands ─────────────────────────────────────────────────────────────────────────────────────────────╮\n│ setup-runtime  Download and setup micromamba runtime for project-local mode.                           │\n│ install-all    Install and register all plugins defined in plugins.yaml.                               │\n│ setup-host     Install interface libraries in the current Python environment.                          │\n│ estimate-size  Estimate disk space required for plugin environments.                                   │\n│ list           List installed plugins from manifest directory.                                         │\n│ remove         Remove a plugin's manifest and conda environment.                                       │\n╰────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n\n\nFor detailed help on any command, use cjm-ctl &lt;command&gt; --help.",
    "crumbs": [
      "cjm-plugin-system"
    ]
  },
  {
    "objectID": "index.html#module-overview",
    "href": "index.html#module-overview",
    "title": "cjm-plugin-system",
    "section": "Module Overview",
    "text": "Module Overview\nDetailed documentation for each module in the project:\n\ncli (cli.ipynb)\n\nCLI tool for declarative plugin management\n\n\nImport\nfrom cjm_plugin_system.cli import (\n    app,\n    main,\n    setup_runtime,\n    run_cmd,\n    install_all,\n    setup_host,\n    estimate_size,\n    list_plugins,\n    remove_plugin\n)\n\n\nFunctions\ndef main(\n    ctx:typer.Context,\n    cjm_config:Annotated[Optional[Path], typer.Option(\n        \"--cjm-config\",\n        help=\"Path to cjm.yaml configuration file\"\n    )]=None,\n    data_dir:Annotated[Optional[Path], typer.Option(\n        \"--data-dir\",\n        help=\"Override data directory (manifests, logs)\"\n    )]=None,\n    conda_prefix:Annotated[Optional[Path], typer.Option(\n        \"--conda-prefix\",\n        help=\"Override conda/mamba prefix path\"\n    )]=None,\n    conda_type:Annotated[Optional[str], typer.Option(\n        \"--conda-type\",\n        help=\"Conda implementation: micromamba, miniforge, or conda\"\n    )]=None,\n) -&gt; None\n    \"CJM Plugin System CLI for managing isolated plugin environments.\"\ndef setup_runtime(\n    force:bool=typer.Option(False, \"--force\", \"-f\", help=\"Re-download even if binary exists\")\n) -&gt; None\n    \"Download and setup micromamba runtime for project-local mode.\"\ndef _check_runtime_available() -&gt; None:\n    \"\"\"Check if the configured conda runtime is available, exit with helpful message if not.\"\"\"\n    cfg = get_config()\n    \n    if not ensure_runtime_available(cfg)\n    \"Check if the configured conda runtime is available, exit with helpful message if not.\"\ndef _get_conda_cmd_str() -&gt; str\n    \"Get the conda/micromamba command string for shell commands.\"\ndef _download_url_to_temp(\n    url: str,  # URL to download\n    suffix: str = \".yml\"  # File suffix for temp file\n) -&gt; Optional[Path]:  # Path to temp file or None if failed\n    \"Download a URL to a temporary file. Returns None if download fails.\"\ndef _resolve_env_file(\n    env_file: str  # Path or URL to environment file\n) -&gt; tuple[str, Optional[Path]]:  # (resolved_path, temp_file_to_cleanup)\n    \"\"\"\n    Resolve env_file to a local path, downloading if it's a URL.\n    \n    Returns (local_path, temp_file) where temp_file is set if we created\n    a temporary file that should be cleaned up later.\n    \"\"\"\ndef run_cmd(\n    cmd: str,  # Shell command to execute\n    check: bool = True  # Whether to raise on non-zero exit\n) -&gt; None\n    \"\"\"\n    Run a shell command and stream output.\n    \n    Uses the platform's default shell (no hardcoded /bin/bash).\n    \"\"\"\ndef _generate_manifest(\n    env_name: str,  # Name of the Conda environment\n    package_name: str,  # Package source string (git URL or package name)\n    manifest_dir: Path  # Directory to write manifest JSON files\n) -&gt; None\n    \"Run introspection script inside the target env to generate manifest.\"\ndef _add_conda_env_to_manifest(\n    manifest_dir:Path, # Directory containing manifest files\n    plugin_name:str, # Plugin name (used for finding manifest file)\n    env_name:str # Conda environment name to add\n) -&gt; bool: # True if successfully updated\n    \"Add conda_env field to an existing manifest file.\"\ndef _conda_env_exists_configured(\n    env_name: str  # Name of the conda environment\n) -&gt; bool:  # True if environment exists\n    \"Check if conda environment exists using configured conda command.\"\ndef install_all(\n    plugins_path:str=typer.Option(\"plugins.yaml\", \"--plugins\", help=\"Path to plugins.yaml file\"),\n    force:bool=typer.Option(False, help=\"Force recreation of environments\")\n) -&gt; None\n    \"Install and register all plugins defined in plugins.yaml.\"\ndef setup_host(\n    plugins_path:str=typer.Option(\"plugins.yaml\", \"--plugins\", help=\"Path to plugins.yaml file\"),\n    yes:bool=typer.Option(False, \"--yes\", \"-y\", help=\"Skip confirmation prompt\")\n) -&gt; None\n    \"Install interface libraries in the current Python environment.\"\ndef _format_size(\n    size_bytes: int  # Size in bytes\n) -&gt; str:  # Human-readable size string\n    \"Format bytes as human-readable string.\"\ndef _get_pypi_size(\n    package_spec: str  # Package name or git URL\n) -&gt; tuple[int, str]:  # (size_bytes, package_name)\n    \"Query PyPI for package download size.\"\ndef _estimate_conda_size(\n    env_file: str,  # Path or URL to environment.yml\n    env_name: str  # Target environment name\n) -&gt; tuple[int, int]:  # (total_bytes, package_count)\n    \"Estimate conda package sizes using dry-run.\"\ndef _estimate_pip_sizes(\n    packages: list[str]  # List of pip package specs\n) -&gt; tuple[int, int, list[tuple[str, int]]]:  # (total_bytes, found_count, [(name, size), ...])\n    \"Estimate pip package sizes from PyPI.\"\ndef estimate_size(\n    plugins_path:str=typer.Option(\"plugins.yaml\", \"--plugins\", help=\"Path to plugins.yaml file\"),\n    plugin_name:Optional[str]=typer.Option(None, \"--plugin\", \"-p\", help=\"Estimate for a single plugin\"),\n    verbose:bool=typer.Option(False, \"--verbose\", \"-v\", help=\"Show per-package breakdown\")\n) -&gt; None\n    \"Estimate disk space required for plugin environments.\"\ndef _get_conda_envs() -&gt; set[str]: # Set of existing conda environment names\n    \"\"\"Get list of existing conda environment names using configured conda command.\"\"\"\n    cfg = get_config()\n    cmd_parts = build_conda_command(cfg, \"env\", \"list\", \"--json\")\n    \n    try\n    \"Get list of existing conda environment names using configured conda command.\"\ndef _get_installed_manifests(\n    manifest_dir:Optional[Path]=None # Directory to scan (uses config default if None)\n) -&gt; list[dict]: # List of manifest dictionaries\n    \"Load all manifest JSON files from the manifest directory.\"\ndef _extract_env_from_python_path(\n    python_path:str # Path like /home/user/miniforge3/envs/my-env/bin/python\n) -&gt; str: # Extracted environment name or empty string\n    \"Extract conda environment name from python_path.\"\ndef list_plugins(\n    plugins_path:Optional[str]=typer.Option(None, \"--plugins\", help=\"Path to plugins.yaml for cross-reference\"),\n    show_envs:bool=typer.Option(False, \"--envs\", \"-e\", help=\"Show conda environment status\")\n) -&gt; None\n    \"List installed plugins from manifest directory.\"\ndef remove_plugin(\n    plugin_name:str=typer.Argument(..., help=\"Name of the plugin to remove\"),\n    plugins_path:Optional[str]=typer.Option(None, \"--plugins\", help=\"Path to plugins.yaml for env name lookup\"),\n    keep_env:bool=typer.Option(False, \"--keep-env\", help=\"Keep the conda environment, only remove manifest\"),\n    yes:bool=typer.Option(False, \"--yes\", \"-y\", help=\"Skip confirmation prompt\")\n) -&gt; None\n    \"Remove a plugin's manifest and conda environment.\"\n\n\n\nConfiguration (config.ipynb)\n\nProject-level configuration for paths, runtime settings, and environment management\n\n\nImport\nfrom cjm_plugin_system.core.config import (\n    RuntimeMode,\n    CondaType,\n    RuntimeConfig,\n    CJMConfig,\n    load_config,\n    get_config,\n    set_config,\n    reset_config\n)\n\n\nFunctions\ndef _load_from_yaml(\n    yaml_path:Path # Path to cjm.yaml file\n) -&gt; CJMConfig: # Parsed configuration\n    \"Load config from YAML file, resolving relative paths.\"\ndef load_config(\n    config_path:Optional[Path]=None, # CLI --cjm-config\n    data_dir:Optional[Path]=None, # CLI --data-dir\n    conda_prefix:Optional[Path]=None, # CLI --conda-prefix\n    conda_type:Optional[str]=None # CLI --conda-type\n) -&gt; CJMConfig: # Resolved configuration\n    \"Load config with layered resolution (CLI &gt; env vars &gt; yaml &gt; defaults).\"\ndef get_config() -&gt; CJMConfig: # Current configuration\n    \"\"\"Get current config (loads defaults if not set).\"\"\"\n    global _current_config\n    if _current_config is None\n    \"Get current config (loads defaults if not set).\"\ndef set_config(\n    config:CJMConfig # Configuration to set as current\n) -&gt; None\n    \"Set current config (called by CLI callback).\"\ndef reset_config() -&gt; None\n    \"Reset to unloaded state (for testing).\"\n\n\nClasses\nclass RuntimeMode(str, Enum):\n    \"Runtime mode for the plugin system.\"\nclass CondaType(str, Enum):\n    \"Type of conda implementation to use.\"\n@dataclass\nclass RuntimeConfig:\n    \"Runtime environment configuration.\"\n    \n    mode: RuntimeMode = RuntimeMode.SYSTEM  # LOCAL for project-local, SYSTEM for global\n    conda_type: CondaType = CondaType.CONDA  # Conda implementation to use\n    prefix: Optional[Path]  # Path to runtime directory (LOCAL mode only)\n    binaries: Dict[str, Path] = field(...)  # Platform-specific binary paths\n@dataclass\nclass CJMConfig:\n    \"Main configuration for cjm-plugin-system.\"\n    \n    runtime: RuntimeConfig = field(...)  # Runtime environment settings\n    data_dir: Path = field(...)  # Base directory for manifests, logs\n    plugins_config: Path = field(...)  # Path to plugins.yaml file\n    models_dir: Optional[Path]  # Directory for model downloads\n    \n    def manifests_dir(self) -&gt; Path: # Directory containing plugin manifests\n            \"\"\"Directory containing plugin manifests.\"\"\"\n            return self.data_dir / \"manifests\"\n    \n        @property\n        def plugin_data_dir(self) -&gt; Path: # Directory for plugin runtime data\n        \"Directory containing plugin manifests.\"\n    \n    def plugin_data_dir(self) -&gt; Path: # Directory for plugin runtime data\n            \"\"\"Directory for plugin runtime data (databases, caches).\"\"\"\n            return self.data_dir / \"data\"\n    \n        @property\n        def logs_dir(self) -&gt; Path: # Directory containing plugin logs\n        \"Directory for plugin runtime data (databases, caches).\"\n    \n    def logs_dir(self) -&gt; Path: # Directory containing plugin logs\n            \"\"\"Directory containing plugin logs.\"\"\"\n            return self.data_dir / \"logs\"\n    \n        @property\n        def conda_binary_path(self) -&gt; Optional[Path]: # Path to conda/micromamba binary or None\n        \"Directory containing plugin logs.\"\n    \n    def conda_binary_path(self) -&gt; Optional[Path]: # Path to conda/micromamba binary or None\n            \"\"\"Get the configured binary path for the current platform.\"\"\"\n            # Inline platform detection to avoid circular imports\n            system = platform_mod.system().lower()\n            machine = platform_mod.machine().lower()\n            \n            if system == \"windows\"\n        \"Get the configured binary path for the current platform.\"\n\n\nVariables\n_current_config: Optional[CJMConfig] = None\n\n\n\nContent Hashing Utilities (hashing.ipynb)\n\nShared cryptographic hashing primitives for content integrity verification\n\n\nImport\nfrom cjm_plugin_system.utils.hashing import (\n    hash_bytes,\n    hash_file,\n    verify_hash\n)\n\n\nFunctions\ndef hash_bytes(\n    content: bytes,  # Byte content to hash\n    algo: str = \"sha256\"  # Hash algorithm name (e.g., \"sha256\", \"sha3_256\")\n) -&gt; str:  # Hash string in \"algo:hexdigest\" format\n    \"Compute a hash of byte content.\"\ndef hash_file(\n    path: Union[str, Path],  # Path to file to hash\n    algo: str = \"sha256\",  # Hash algorithm name\n    chunk_size: int = 8192  # Read chunk size in bytes\n) -&gt; str:  # Hash string in \"algo:hexdigest\" format\n    \"Stream-hash a file without loading it entirely into memory.\"\ndef verify_hash(\n    content: bytes,  # Content to verify\n    expected: str  # Expected hash in \"algo:hexdigest\" format\n) -&gt; bool:  # True if content matches expected hash\n    \"Verify content against an expected hash string.\"\n\n\n\nPlugin Interface (interface.ipynb)\n\nAbstract base class defining the generic plugin interface\n\n\nImport\nfrom cjm_plugin_system.core.interface import (\n    FileBackedDTO,\n    PluginInterface\n)\n\n\nClasses\n@runtime_checkable\nclass FileBackedDTO(Protocol):\n    \"Protocol for Data Transfer Objects that serialize to disk for zero-copy transfer.\"\n    \n    def to_temp_file(self) -&gt; str: # Absolute path to the temporary file\n        \"Save the data to a temporary file and return the absolute path.\"\nclass PluginInterface(ABC):\n    \"Abstract base class for all plugins (both local workers and remote proxies).\"\n    \n    def name(self) -&gt; str: # Unique identifier for this plugin\n            \"\"\"Unique plugin identifier.\"\"\"\n            ...\n    \n        @property\n        @abstractmethod\n        def version(self) -&gt; str: # Semantic version string (e.g., \"1.0.0\")\n        \"Unique plugin identifier.\"\n    \n    def version(self) -&gt; str: # Semantic version string (e.g., \"1.0.0\")\n            \"\"\"Plugin version.\"\"\"\n            ...\n    \n        @abstractmethod\n        def initialize(\n            self,\n            config: Optional[Dict[str, Any]] = None # Configuration dictionary\n        ) -&gt; None\n        \"Plugin version.\"\n    \n    def initialize(\n            self,\n            config: Optional[Dict[str, Any]] = None # Configuration dictionary\n        ) -&gt; None\n        \"Initialize or re-configure the plugin.\"\n    \n    def execute(\n            self,\n            *args,\n            **kwargs\n        ) -&gt; Any: # Plugin-specific output\n        \"Execute the plugin's main functionality.\"\n    \n    def execute_stream(\n            self,\n            *args,\n            **kwargs\n        ) -&gt; Generator[Any, None, None]: # Yields partial results\n        \"Stream execution results chunk by chunk.\"\n    \n    def get_config_schema(self) -&gt; Dict[str, Any]: # JSON Schema for configuration\n            \"\"\"Return JSON Schema describing the plugin's configuration options.\"\"\"\n            ...\n    \n        @abstractmethod\n        def get_current_config(self) -&gt; Dict[str, Any]: # Current configuration values\n        \"Return JSON Schema describing the plugin's configuration options.\"\n    \n    def get_current_config(self) -&gt; Dict[str, Any]: # Current configuration values\n            \"\"\"Return the current configuration state as a dictionary.\"\"\"\n            ...\n    \n        @abstractmethod\n        def cleanup(self) -&gt; None\n        \"Return the current configuration state as a dictionary.\"\n    \n    def cleanup(self) -&gt; None:\n            \"\"\"Clean up resources when plugin is unloaded.\"\"\"\n            ...\n    \n        def cancel(self) -&gt; None\n        \"Clean up resources when plugin is unloaded.\"\n    \n    def cancel(self) -&gt; None:\n            \"\"\"Cancel the current execution. Override for cooperative cancellation support.\"\"\"\n            pass  # Default: no-op (plugins opt-in to cancellation)\n        \"Cancel the current execution. Override for cooperative cancellation support.\"\n    \n    def report_progress(\n            self,\n            progress: float, # 0.0 to 1.0, or -1.0 for indeterminate\n            message: str = \"\" # Descriptive status message\n        ) -&gt; None\n        \"Report execution progress. Call during execute() to update status.\"\n\n\n\nPlugin Manager (manager.ipynb)\n\nPlugin discovery, loading, and lifecycle management system\n\n\nImport\nfrom cjm_plugin_system.core.manager import (\n    PluginManager,\n    get_plugin_config,\n    get_plugin_config_schema,\n    get_all_plugin_configs,\n    update_plugin_config,\n    reload_plugin,\n    get_plugin_stats,\n    execute_plugin_stream\n)\n\n\nFunctions\ndef get_plugin_config(\n    self,\n    plugin_name: str # Name of the plugin\n) -&gt; Optional[Dict[str, Any]]: # Current configuration or None\n    \"Get the current configuration of a plugin.\"\ndef get_plugin_config_schema(\n    self,\n    plugin_name: str # Name of the plugin\n) -&gt; Optional[Dict[str, Any]]: # JSON Schema or None\n    \"Get the configuration JSON Schema for a plugin.\"\ndef get_all_plugin_configs(self) -&gt; Dict[str, Dict[str, Any]]: # Plugin name -&gt; config mapping\n    \"\"\"Get current configuration for all loaded plugins.\"\"\"\n    return {\n        name: plugin.get_current_config()\n    \"Get current configuration for all loaded plugins.\"\ndef update_plugin_config(\n    self,\n    plugin_name: str, # Name of the plugin\n    config: Dict[str, Any] # New configuration values\n) -&gt; bool: # True if successful\n    \"Update a plugin's configuration (hot-reload without restart).\"\ndef reload_plugin(\n    self,\n    plugin_name: str, # Name of the plugin\n    config: Optional[Dict[str, Any]] = None # Optional new configuration\n) -&gt; bool: # True if successful\n    \"Reload a plugin by terminating and restarting its Worker.\"\ndef get_plugin_stats(\n    self,\n    plugin_name: str # Name of the plugin\n) -&gt; Optional[Dict[str, Any]]: # Resource telemetry or None\n    \"Get resource usage stats for a plugin's Worker process.\"\nasync def execute_plugin_stream(\n    self,\n    plugin_name: str,  # Name of the plugin\n    *args,\n    **kwargs\n) -&gt; AsyncGenerator[Any, None]:  # Async generator yielding results\n    \"Execute a plugin with streaming response.\"\n\n\nClasses\nclass PluginManager:\n    def __init__(\n        self,\n        plugin_interface:Type[PluginInterface]=PluginInterface, # Base interface for type checking\n        search_paths:Optional[List[Path]]=None, # Custom manifest search paths\n        scheduler:Optional[ResourceScheduler]=None # Resource allocation policy\n    )\n    \"Manages plugin discovery, loading, and lifecycle via process isolation.\"\n    \n    def __init__(\n            self,\n            plugin_interface:Type[PluginInterface]=PluginInterface, # Base interface for type checking\n            search_paths:Optional[List[Path]]=None, # Custom manifest search paths\n            scheduler:Optional[ResourceScheduler]=None # Resource allocation policy\n        )\n        \"Initialize the plugin manager.\"\n    \n    def register_system_monitor(\n            self,\n            plugin_name:str # Name of the system monitor plugin\n        ) -&gt; None\n        \"Bind a loaded plugin to act as the hardware system monitor.\"\n    \n    def discover_manifests(self) -&gt; List[PluginMeta]: # List of discovered plugin metadata\n            \"\"\"Discover plugins via JSON manifests in search paths.\"\"\"\n            self.discovered = []\n            seen_plugins = set()\n    \n            for base_path in self.search_paths\n        \"Discover plugins via JSON manifests in search paths.\"\n    \n    def get_discovered_by_category(\n            self,\n            category:str # Category to filter by (e.g., \"transcription\")\n        ) -&gt; List[PluginMeta]: # List of matching discovered plugins\n        \"Get discovered plugins filtered by category.\"\n    \n    def get_plugins_by_category(\n            self,\n            category:str # Category to filter by (e.g., \"transcription\")\n        ) -&gt; List[PluginMeta]: # List of matching loaded plugins\n        \"Get loaded plugins filtered by category.\"\n    \n    def get_discovered_categories(self) -&gt; List[str]: # List of unique categories\n            \"\"\"Get all unique categories among discovered plugins.\"\"\"\n            return list(set(meta.category for meta in self.discovered if meta.category))\n    \n        def get_loaded_categories(self) -&gt; List[str]: # List of unique categories\n        \"Get all unique categories among discovered plugins.\"\n    \n    def get_loaded_categories(self) -&gt; List[str]: # List of unique categories\n            \"\"\"Get all unique categories among loaded plugins.\"\"\"\n            return list(set(meta.category for meta in self.plugins.values() if meta.category))\n    \n        def get_plugin_meta(\n            self,\n            plugin_name:str # Name of the plugin\n        ) -&gt; Optional[PluginMeta]: # Plugin metadata or None\n        \"Get all unique categories among loaded plugins.\"\n    \n    def get_plugin_meta(\n            self,\n            plugin_name:str # Name of the plugin\n        ) -&gt; Optional[PluginMeta]: # Plugin metadata or None\n        \"Get metadata for a loaded plugin by name.\"\n    \n    def get_discovered_meta(\n            self,\n            plugin_name:str # Name of the plugin\n        ) -&gt; Optional[PluginMeta]: # Plugin metadata or None\n        \"Get metadata for a discovered (not necessarily loaded) plugin by name.\"\n    \n    def load_plugin(\n            self,\n            plugin_meta:PluginMeta, # Plugin metadata (with manifest attached)\n            config:Optional[Dict[str, Any]]=None # Initial configuration\n        ) -&gt; bool: # True if successfully loaded\n        \"Load a plugin by spawning a Worker subprocess.\"\n    \n    def load_all(\n            self,\n            configs:Optional[Dict[str, Dict[str, Any]]]=None # Plugin name -&gt; config mapping\n        ) -&gt; Dict[str, bool]: # Plugin name -&gt; success mapping\n        \"Discover and load all available plugins.\"\n    \n    def unload_plugin(\n            self,\n            plugin_name:str # Name of the plugin to unload\n        ) -&gt; bool: # True if successfully unloaded\n        \"Unload a plugin and terminate its Worker process.\"\n    \n    def unload_all(self) -&gt; None:\n            \"\"\"Unload all plugins and terminate all Worker processes.\"\"\"\n            for name in list(self.plugins.keys())\n        \"Unload all plugins and terminate all Worker processes.\"\n    \n    def get_plugin(\n            self,\n            plugin_name:str # Name of the plugin\n        ) -&gt; Optional[PluginInterface]: # Plugin proxy instance or None\n        \"Get a loaded plugin instance by name.\"\n    \n    def list_plugins(self) -&gt; List[PluginMeta]: # List of loaded plugin metadata\n            \"\"\"List all loaded plugins.\"\"\"\n            return list(self.plugins.values())\n    \n        def _evict_for_resources(self, needed_meta:PluginMeta) -&gt; bool\n        \"List all loaded plugins.\"\n    \n    def execute_plugin(\n            self,\n            plugin_name:str, # Name of the plugin\n            *args,\n            **kwargs\n        ) -&gt; Any: # Plugin result\n        \"Execute a plugin's main functionality (sync).\"\n    \n    async def execute_plugin_async(\n            self,\n            plugin_name:str, # Name of the plugin\n            *args,\n            **kwargs\n        ) -&gt; Any: # Plugin result\n        \"Execute a plugin's main functionality (async).\"\n    \n    def enable_plugin(\n            self,\n            plugin_name:str # Name of the plugin\n        ) -&gt; bool: # True if plugin was enabled\n        \"Enable a plugin.\"\n    \n    def disable_plugin(\n            self,\n            plugin_name:str # Name of the plugin\n        ) -&gt; bool: # True if plugin was disabled\n        \"Disable a plugin without unloading it.\"\n    \n    def get_plugin_logs(\n            self,\n            plugin_name:str, # Name of the plugin\n            lines:int=50 # Number of lines to return\n        ) -&gt; str: # Log content\n        \"Read the last N lines of the plugin's log file.\"\n\n\n\nPlugin Metadata (metadata.ipynb)\n\nData structures for plugin metadata\n\n\nImport\nfrom cjm_plugin_system.core.metadata import (\n    PluginMeta\n)\n\n\nClasses\n@dataclass\nclass PluginMeta:\n    \"Metadata about a plugin.\"\n    \n    name: str  # Plugin's unique identifier\n    version: str  # Plugin's version string\n    description: str = ''  # Brief description of the plugin's functionality\n    author: str = ''  # Plugin author's name or organization\n    package_name: str = ''  # Python package name containing the plugin\n    category: str = ''  # Plugin category (e.g., \"transcription\", \"system_monitor\")\n    interface: str = ''  # Fully qualified interface class name\n    config_schema: Optional[Dict[str, Any]]  # JSON Schema for plugin configuration\n    instance: Optional[Any]  # Plugin instance (PluginInterface subclass)\n    enabled: bool = True  # Whether the plugin is enabled\n    last_executed: float = 0.0  # Unix timestamp\n\n\n\nPlatform Utilities (platform.ipynb)\n\nCross-platform utilities for process management, path handling, and system detection\n\n\nImport\nfrom cjm_plugin_system.core.platform import (\n    MICROMAMBA_URLS,\n    is_windows,\n    is_macos,\n    is_linux,\n    is_apple_silicon,\n    get_current_platform,\n    get_python_in_env,\n    get_popen_isolation_kwargs,\n    terminate_process,\n    terminate_self,\n    run_shell_command,\n    conda_env_exists,\n    get_micromamba_download_url,\n    download_micromamba,\n    get_conda_command,\n    build_conda_command,\n    get_micromamba_binary_path,\n    ensure_runtime_available\n)\n\n\nFunctions\ndef is_windows() -&gt; bool:\n    \"\"\"Check if running on Windows.\"\"\"\n    return platform.system() == \"Windows\"\n\n\ndef is_macos() -&gt; bool\n    \"Check if running on Windows.\"\ndef is_macos() -&gt; bool:\n    \"\"\"Check if running on macOS.\"\"\"\n    return platform.system() == \"Darwin\"\n\n\ndef is_linux() -&gt; bool\n    \"Check if running on macOS.\"\ndef is_linux() -&gt; bool:\n    \"\"\"Check if running on Linux.\"\"\"\n    return platform.system() == \"Linux\"\n\n\ndef is_apple_silicon() -&gt; bool\n    \"Check if running on Linux.\"\ndef is_apple_silicon() -&gt; bool\n    \"Check if running on Apple Silicon Mac (for MPS detection).\"\ndef get_current_platform() -&gt; str:\n    \"\"\"Get current platform string for manifest filtering.\n    \n    Returns strings like 'linux-x64', 'darwin-arm64', 'win-x64'.\n    \"\"\"\n    system = platform.system().lower()\n    machine = platform.machine().lower()\n    \n    # Normalize system names\n    if system == \"darwin\"\n    \"\"\"\n    Get current platform string for manifest filtering.\n    \n    Returns strings like 'linux-x64', 'darwin-arm64', 'win-x64'.\n    \"\"\"\ndef get_python_in_env(\n    env_path: Path  # Path to conda environment root\n) -&gt; Path:  # Path to Python executable\n    \"\"\"\n    Get the Python executable path for a conda environment.\n    \n    On Windows: env_path/python.exe\n    On Unix: env_path/bin/python\n    \"\"\"\ndef get_popen_isolation_kwargs() -&gt; Dict[str, Any]:\n    \"\"\"Return kwargs for process isolation in subprocess.Popen.\n    \n    On Unix: Returns {'start_new_session': True}\n    On Windows: Returns {'creationflags': CREATE_NEW_PROCESS_GROUP}\n    \n    Usage:\n        process = subprocess.Popen(cmd, **get_popen_isolation_kwargs(), ...)\n    \"\"\"\n    if is_windows()\n    \"\"\"\n    Return kwargs for process isolation in subprocess.Popen.\n    \n    On Unix: Returns {'start_new_session': True}\n    On Windows: Returns {'creationflags': CREATE_NEW_PROCESS_GROUP}\n    \n    Usage:\n        process = subprocess.Popen(cmd, **get_popen_isolation_kwargs(), ...)\n    \"\"\"\ndef terminate_process(\n    process: subprocess.Popen,  # Process to terminate\n    timeout: float = 2.0  # Seconds to wait before force kill\n) -&gt; None\n    \"\"\"\n    Terminate a subprocess gracefully, with fallback to force kill.\n    \n    On all platforms:\n    1. Calls process.terminate() (SIGTERM on Unix, TerminateProcess on Windows)\n    2. Waits for timeout seconds\n    3. If still running, calls process.kill() (SIGKILL on Unix, TerminateProcess on Windows)\n    \"\"\"\ndef terminate_self() -&gt; None:\n    \"\"\"Terminate the current process (for worker suicide pact).\n    \n    On Unix: Sends SIGTERM to self for graceful shutdown\n    On Windows: Calls os._exit() since Windows lacks SIGTERM\n    \"\"\"\n    if is_windows()\n    \"\"\"\n    Terminate the current process (for worker suicide pact).\n    \n    On Unix: Sends SIGTERM to self for graceful shutdown\n    On Windows: Calls os._exit() since Windows lacks SIGTERM\n    \"\"\"\ndef run_shell_command(\n    cmd: str,  # Shell command to execute\n    check: bool = True,  # Whether to raise on non-zero exit\n    capture_output: bool = False,  # Whether to capture stdout/stderr\n    **kwargs  # Additional kwargs passed to subprocess.run\n) -&gt; subprocess.CompletedProcess\n    \"\"\"\n    Run a shell command cross-platform.\n    \n    Unlike using shell=True with executable='/bin/bash', this function\n    uses the platform's default shell:\n    - Linux/macOS: /bin/sh (or $SHELL)\n    - Windows: cmd.exe\n    \"\"\"\ndef conda_env_exists(\n    env_name: str,  # Name of the conda environment\n    conda_cmd: str = \"conda\"  # Conda command (conda, mamba, micromamba)\n) -&gt; bool\n    \"\"\"\n    Check if a conda environment exists (cross-platform).\n    \n    Uses 'conda env list --json' instead of piping to grep,\n    which doesn't work on Windows.\n    \"\"\"\ndef get_micromamba_download_url(\n    platform_str: Optional[str] = None  # Platform string (e.g., 'linux-x64'), uses current if None\n) -&gt; str:  # Download URL for micromamba binary\n    \"Get the micromamba download URL for the specified or current platform.\"\ndef download_micromamba(\n    dest_path: Path,  # Destination path for the micromamba binary\n    platform_str: Optional[str] = None,  # Platform string, uses current if None\n    show_progress: bool = True  # Whether to print progress messages\n) -&gt; bool:  # True if download succeeded\n    \"Download and extract micromamba binary to the specified path.\"\ndef get_conda_command(\n    config: CJMConfig  # Configuration object with runtime settings\n) -&gt; List[str]:  # Base command with prefix args if needed\n    \"Get the conda/mamba/micromamba base command with prefix args for local mode.\"\ndef build_conda_command(\n    config: CJMConfig,  # Configuration object with runtime settings\n    *args: str  # Additional command arguments\n) -&gt; List[str]:  # Complete command ready for subprocess\n    \"Build a complete conda/mamba/micromamba command.\"\ndef get_micromamba_binary_path(\n    config: CJMConfig  # Configuration object with runtime settings\n) -&gt; Optional[Path]:  # Path to micromamba binary or None\n    \"Get the configured micromamba binary path for the current platform.\"\ndef ensure_runtime_available(\n    config: CJMConfig  # Configuration object with runtime settings\n) -&gt; bool:  # True if runtime is available\n    \"Check if the configured conda/micromamba runtime is available.\"\n\n\nVariables\nMICROMAMBA_URLS: Dict[str, str]\n\n\n\nRemote Plugin Proxy (proxy.ipynb)\n\nBridge between Host application and isolated Worker processes\n\n\nImport\nfrom cjm_plugin_system.core.proxy import (\n    RemotePluginProxy,\n    execute_async,\n    execute_stream_sync,\n    execute_stream,\n    get_stats,\n    is_alive,\n    cancel,\n    cancel_async,\n    get_progress,\n    get_progress_async\n)\n\n\nFunctions\ndef _maybe_serialize_input(\n    self,\n    obj: Any # Object to potentially serialize\n) -&gt; Any: # Serialized form (path string or original object)\n    \"Convert FileBackedDTO objects to file paths for zero-copy transfer.\"\ndef _prepare_payload(\n    self,\n    args: tuple, # Positional arguments\n    kwargs: dict # Keyword arguments\n) -&gt; Dict[str, Any]: # JSON-serializable payload\n    \"Prepare arguments for HTTP transmission.\"\nasync def execute_async(\n    self,\n    *args,\n    **kwargs\n) -&gt; Any: # Plugin result\n    \"Execute the plugin asynchronously.\"\ndef execute_stream_sync(self, *args, **kwargs) -&gt; Generator[Any, None, None]\n    \"Synchronous wrapper for streaming (blocking).\"\nasync def execute_stream(\n    self,\n    *args,\n    **kwargs\n) -&gt; AsyncGenerator[Any, None]: # Yields parsed JSON chunks\n    \"Execute with streaming response (async generator).\"\ndef get_stats(self) -&gt; Dict[str, Any]: # Process telemetry\n    \"\"\"Get worker process resource usage.\"\"\"\n    with httpx.Client() as client\n    \"Get worker process resource usage.\"\ndef is_alive(self) -&gt; bool: # True if worker is responsive\n    \"\"\"Check if the worker process is still running and responsive.\"\"\"\n    if not self.process or self.process.poll() is not None\n    \"Check if the worker process is still running and responsive.\"\ndef cancel(self) -&gt; bool: # True if cancel request was sent\n    \"\"\"Request cancellation of running execution.\"\"\"\n    try\n    \"Request cancellation of running execution.\"\nasync def cancel_async(self) -&gt; bool: # True if cancel request was sent\n    \"\"\"Request cancellation asynchronously.\"\"\"\n    try\n    \"Request cancellation asynchronously.\"\ndef get_progress(self) -&gt; Dict[str, Any]: # {progress: float, message: str}\n    \"\"\"Get current execution progress from worker.\"\"\"\n    try\n    \"Get current execution progress from worker.\"\nasync def get_progress_async(self) -&gt; Dict[str, Any]: # {progress: float, message: str}\n    \"\"\"Get current execution progress asynchronously.\"\"\"\n    try\n    \"Get current execution progress asynchronously.\"\ndef __enter__(self):\n    \"\"\"Enter context manager.\"\"\"\n    return self\n\ndef __exit__(self, exc_type, exc_val, exc_tb)\n    \"Enter context manager.\"\ndef __exit__(self, exc_type, exc_val, exc_tb):\n    \"\"\"Exit context manager and cleanup.\"\"\"\n    self.cleanup()\n    return False\n\nasync def __aenter__(self)\n    \"Exit context manager and cleanup.\"\nasync def __aenter__(self):\n    \"\"\"Enter async context manager.\"\"\"\n    return self\n\nasync def __aexit__(self, exc_type, exc_val, exc_tb)\n    \"Enter async context manager.\"\nasync def __aexit__(self, exc_type, exc_val, exc_tb)\n    \"Exit async context manager and cleanup.\"\n\n\nClasses\nclass RemotePluginProxy:\n    def __init__(\n        self,\n        manifest:Dict[str, Any] # Plugin manifest with python_path, module, class, etc.\n    )\n    \"Proxy that forwards plugin calls to an isolated Worker subprocess.\"\n    \n    def __init__(\n            self,\n            manifest:Dict[str, Any] # Plugin manifest with python_path, module, class, etc.\n        )\n        \"Initialize proxy and start the worker process.\"\n    \n    def name(self) -&gt; str: # Plugin name from manifest\n            \"\"\"Plugin name.\"\"\"\n            return self.manifest.get('name', 'unknown')\n        \n        @property\n        def version(self) -&gt; str: # Plugin version from manifest\n        \"Plugin name.\"\n    \n    def version(self) -&gt; str: # Plugin version from manifest\n            \"\"\"Plugin version.\"\"\"\n            return self.manifest.get('version', '0.0.0')\n    \n        def _get_free_port(self) -&gt; int\n        \"Plugin version.\"\n    \n    def initialize(\n            self,\n            config:Optional[Dict[str, Any]]=None # Configuration dictionary\n        ) -&gt; None\n        \"Initialize or reconfigure the plugin.\"\n    \n    def execute(\n            self,\n            *args,\n            **kwargs\n        ) -&gt; Any: # Plugin result\n        \"Execute the plugin synchronously.\"\n    \n    def get_config_schema(self) -&gt; Dict[str, Any]: # JSON Schema\n            \"\"\"Get the plugin's configuration schema.\"\"\"\n            with httpx.Client() as client\n        \"Get the plugin's configuration schema.\"\n    \n    def get_current_config(self) -&gt; Dict[str, Any]: # Current config values\n            \"\"\"Get the plugin's current configuration.\"\"\"\n            with httpx.Client() as client\n        \"Get the plugin's current configuration.\"\n    \n    def cleanup(self) -&gt; None:\n            \"\"\"Clean up plugin resources and terminate worker process.\"\"\"\n            # Send cleanup request to worker\n            try\n        \"Clean up plugin resources and terminate worker process.\"\n\n\n\nJob Queue (queue.ipynb)\n\nResource-aware job queue for sequential plugin execution with cancellation support\n\n\nImport\nfrom cjm_plugin_system.core.queue import (\n    JobStatus,\n    Job,\n    JobQueue,\n    submit,\n    cancel,\n    reorder,\n    get_job,\n    wait_for_job,\n    get_state,\n    get_job_logs,\n    start,\n    stop\n)\n\n\nFunctions\nasync def submit(\n    self,\n    plugin_name: str,  # Target plugin\n    *args,\n    priority: int = 0,  # Higher = more urgent\n    **kwargs\n) -&gt; str:  # Returns job_id\n    \"Submit a job to the queue.\"\nasync def cancel(\n    self,\n    job_id: str  # Job to cancel\n) -&gt; bool:  # True if cancelled\n    \"Cancel a pending or running job.\"\ndef reorder(\n    self,\n    job_id: str,  # Job to move\n    new_priority: int  # New priority value\n) -&gt; bool:  # True if reordered\n    \"Change the priority of a pending job.\"\ndef get_job(\n    self,\n    job_id: str  # Job to retrieve\n) -&gt; Optional[Job]:  # Job or None\n    \"Get a job by ID.\"\nasync def wait_for_job(\n    self,\n    job_id: str,  # Job to wait for\n    timeout: Optional[float] = None  # Max seconds to wait\n) -&gt; Job:  # Completed/failed/cancelled job\n    \"Wait for a job to complete.\"\ndef get_state(self) -&gt; Dict[str, Any]:  # Queue state for UI\n    \"\"\"Get the current queue state.\"\"\"\n    running_dict = None\n    if self._running\n    \"Get the current queue state.\"\ndef get_job_logs(\n    self,\n    job_id: str,  # Job to get logs for\n    lines: int = 100  # Max lines to return\n) -&gt; str:  # Log content\n    \"Get logs for a job from the plugin's log file.\"\nasync def start(self) -&gt; None:\n    \"\"\"Start the queue processor.\"\"\"\n    if self._running_flag\n    \"Start the queue processor.\"\nasync def stop(self) -&gt; None:\n    \"\"\"Stop the queue processor gracefully.\"\"\"\n    self._running_flag = False\n    self._job_available.set()  # Wake up the processor\n    \n    if self._processor_task\n    \"Stop the queue processor gracefully.\"\ndef _move_to_history(self, job: Job) -&gt; None:\n    \"\"\"Move a job to history, maintaining max_history limit.\"\"\"\n    self._history.append(job)\n    if len(self._history) &gt; self.max_history\n    \"Move a job to history, maintaining max_history limit.\"\ndef _signal_job_completed(self, job_id: str) -&gt; None:\n    \"\"\"Signal that a job has completed.\"\"\"\n    event = self._job_completed_events.get(job_id)\n    if event\n    \"Signal that a job has completed.\"\nasync def _process_loop(self) -&gt; None:\n    \"\"\"Main processing loop.\"\"\"\n    while self._running_flag\n    \"Main processing loop.\"\nasync def _execute_job(self, job: Job) -&gt; None:\n    \"\"\"Execute a single job.\"\"\"\n    self.logger.info(f\"Starting job {job.id[:8]} ({job.plugin_name})\")\n    \n    # Mark as running\n    job.status = JobStatus.running\n    job.started_at = time.time()\n    self._running = job\n    \n    try\n    \"Execute a single job.\"\nasync def _execute_with_cancellation(\n    self,\n    job: Job,\n    plugin: Any\n) -&gt; Any\n    \"Execute job with cancellation monitoring.\"\nasync def _poll_progress(\n    self,\n    job: Job,\n    plugin: Any\n) -&gt; None\n    \"Poll progress from the plugin during execution.\"\n\n\nClasses\nclass JobStatus(str, Enum):\n    \"Status of a job in the queue.\"\n@dataclass\nclass Job:\n    \"A queued plugin execution request.\"\n    \n    id: str  # Unique job identifier (UUID)\n    plugin_name: str  # Target plugin name\n    args: Tuple[Any, ...]  # Positional arguments for execute()\n    kwargs: Dict[str, Any]  # Keyword arguments for execute()\n    status: JobStatus = JobStatus.pending  # Current job status\n    priority: int = 0  # Higher = more urgent\n    created_at: float = field(...)  # Submission timestamp\n    started_at: Optional[float]  # Execution start timestamp\n    completed_at: Optional[float]  # Completion timestamp\n    result: Any  # Execution result (if completed)\n    error: Optional[str]  # Error message (if failed)\n    progress: float = 0.0  # 0.0 to 1.0, or -1.0 for indeterminate\n    status_message: str = ''  # Descriptive status message\n    \nclass JobQueue:\n    def __init__(\n        self,\n        manager: PluginManager,  # Plugin manager instance\n        max_history: int = 100,  # Max completed jobs to retain\n        cancel_timeout: float = 3.0,  # Seconds to wait for cooperative cancel\n        progress_poll_interval: float = 1.0  # Seconds between progress polls\n    )\n    \"Resource-aware job queue for sequential plugin execution.\"\n    \n    def __init__(\n            self,\n            manager: PluginManager,  # Plugin manager instance\n            max_history: int = 100,  # Max completed jobs to retain\n            cancel_timeout: float = 3.0,  # Seconds to wait for cooperative cancel\n            progress_poll_interval: float = 1.0  # Seconds between progress polls\n        )\n        \"Initialize the job queue.\"\n\n\n\nScheduling (scheduling.ipynb)\n\nResource scheduling policies for plugin execution\n\n\nImport\nfrom cjm_plugin_system.core.scheduling import (\n    ResourceScheduler,\n    PermissiveScheduler,\n    SafetyScheduler,\n    QueueScheduler\n)\n\n\nClasses\nclass ResourceScheduler(ABC):\n    \"Abstract base class for resource allocation policies.\"\n    \n    def allocate(\n            self,\n            plugin_meta: PluginMeta,  # Metadata of the plugin requesting resources\n            stats_provider: Callable[[], Dict[str, Any]]  # Function that returns fresh stats\n        ) -&gt; bool:  # True if execution is allowed\n        \"Decide if a plugin can start based on its requirements and system state.\"\n    \n    async def allocate_async(\n            self,\n            plugin_meta: PluginMeta,  # Metadata of the plugin requesting resources\n            stats_provider: Callable[[], Awaitable[Dict[str, Any]]]  # Async function returning stats\n        ) -&gt; bool:  # True if execution is allowed\n        \"Async allocation decision. Default delegates to sync allocate after fetching stats once.\"\n    \n    def on_execution_start(\n            self,\n            plugin_name: str  # Name of the plugin starting execution\n        ) -&gt; None\n        \"Notify scheduler that a task started (to reserve resources).\"\n    \n    def on_execution_finish(\n            self,\n            plugin_name: str  # Name of the plugin finishing execution\n        ) -&gt; None\n        \"Notify scheduler that a task finished (to release resources).\"\nclass PermissiveScheduler(ResourceScheduler):\n    \"Scheduler that allows all executions (Default / Dev Mode).\"\n    \n    def allocate(\n            self,\n            plugin_meta: PluginMeta,  # Metadata of the plugin requesting resources\n            stats_provider: Callable[[], Dict[str, Any]]  # Stats provider (ignored)\n        ) -&gt; bool:  # Always returns True\n        \"Allow all plugin executions without checking resources.\"\n    \n    def on_execution_start(\n            self,\n            plugin_name: str  # Name of the plugin starting execution\n        ) -&gt; None\n        \"No-op for permissive scheduler.\"\n    \n    def on_execution_finish(\n            self,\n            plugin_name: str  # Name of the plugin finishing execution\n        ) -&gt; None\n        \"No-op for permissive scheduler.\"\nclass SafetyScheduler(ResourceScheduler):\n    \"Scheduler that prevents execution if resources are insufficient.\"\n    \n    def allocate(\n            self,\n            plugin_meta: PluginMeta,  # Metadata of the plugin requesting resources\n            stats_provider: Callable[[], Dict[str, Any]]  # Function returning current stats\n        ) -&gt; bool:  # True if resources are available\n        \"Check resource requirements against system state.\"\n    \n    def on_execution_start(\n            self,\n            plugin_name: str  # Name of the plugin starting execution\n        ) -&gt; None\n        \"Called when execution starts (for future resource reservation).\"\n    \n    def on_execution_finish(\n            self,\n            plugin_name: str  # Name of the plugin finishing execution\n        ) -&gt; None\n        \"Called when execution finishes (for future resource release).\"\nclass QueueScheduler:\n    def __init__(\n        self,\n        timeout: float = 300.0,  # Max seconds to wait for resources\n        poll_interval: float = 2.0  # Seconds between resource checks\n    )\n    \"Scheduler that waits for resources to become available.\"\n    \n    def __init__(\n            self,\n            timeout: float = 300.0,  # Max seconds to wait for resources\n            poll_interval: float = 2.0  # Seconds between resource checks\n        )\n        \"Initialize queue scheduler with timeout and polling settings.\"\n    \n    def allocate(\n            self,\n            plugin_meta: PluginMeta,  # Metadata of the plugin requesting resources\n            stats_provider: Callable[[], Dict[str, Any]]  # Function returning current stats\n        ) -&gt; bool:  # True if resources become available before timeout\n        \"Wait for resources using blocking sleep.\"\n    \n    async def allocate_async(\n            self,\n            plugin_meta: PluginMeta,  # Metadata of the plugin requesting resources\n            stats_provider: Callable[[], Awaitable[Dict[str, Any]]]  # Async stats function\n        ) -&gt; bool:  # True if resources become available before timeout\n        \"Wait for resources using non-blocking async sleep.\"\n    \n    def on_execution_start(\n            self,\n            plugin_name: str  # Name of the plugin starting execution\n        ) -&gt; None\n        \"Track that a plugin has started executing.\"\n    \n    def on_execution_finish(\n            self,\n            plugin_name: str  # Name of the plugin finishing execution\n        ) -&gt; None\n        \"Track that a plugin has finished executing.\"\n    \n    def get_active_plugins(self) -&gt; Set[str]:  # Set of currently executing plugin names\n        \"Get the set of plugins with active executions.\"\n\n\n\nConfiguration Validation (validation.ipynb)\n\nValidation helpers for plugin configuration dataclasses\n\n\nImport\nfrom cjm_plugin_system.utils.validation import (\n    T,\n    SCHEMA_TITLE,\n    SCHEMA_DESC,\n    SCHEMA_MIN,\n    SCHEMA_MAX,\n    SCHEMA_ENUM,\n    SCHEMA_MIN_LEN,\n    SCHEMA_MAX_LEN,\n    SCHEMA_PATTERN,\n    SCHEMA_FORMAT,\n    validate_field_value,\n    validate_config,\n    config_to_dict,\n    dict_to_config,\n    extract_defaults,\n    dataclass_to_jsonschema\n)\n\n\nFunctions\ndef validate_field_value(\n    value:Any, # Value to validate\n    metadata:Dict[str, Any], # Field metadata containing constraints\n    field_name:str=\"\" # Field name for error messages\n) -&gt; Tuple[bool, Optional[str]]: # (is_valid, error_message)\n    \"Validate a value against field metadata constraints.\"\ndef validate_config(\n    config:Any # Configuration dataclass instance to validate\n) -&gt; Tuple[bool, Optional[str]]: # (is_valid, error_message)\n    \"Validate all fields in a configuration dataclass against their metadata constraints.\"\ndef config_to_dict(\n    config:Any # Configuration dataclass instance\n) -&gt; Dict[str, Any]: # Dictionary representation of the configuration\n    \"Convert a configuration dataclass instance to a dictionary.\"\ndef dict_to_config(\n    config_class:Type[T], # Configuration dataclass type\n    data:Optional[Dict[str, Any]]=None, # Dictionary with configuration values\n    validate:bool=False # Whether to validate against metadata constraints\n) -&gt; T: # Instance of the configuration dataclass\n    \"Create a configuration dataclass instance from a dictionary.\"\ndef extract_defaults(\n    config_class:Type # Configuration dataclass type\n) -&gt; Dict[str, Any]: # Default values from the dataclass\n    \"Extract default values from a configuration dataclass type.\"\ndef _python_type_to_json_type(\n    python_type:type # Python type annotation to convert\n) -&gt; Dict[str, Any]: # JSON schema type definition\n    \"Convert Python type to JSON schema type.\"\ndef dataclass_to_jsonschema(\n    cls:type # Dataclass with field metadata\n) -&gt; Dict[str, Any]: # JSON schema dictionary\n    \"Convert a dataclass to a JSON schema for form generation.\"\n\n\nVariables\nT\nSCHEMA_TITLE = 'title'  # Display title for the field\nSCHEMA_DESC = 'description'  # Help text description\nSCHEMA_MIN = 'minimum'  # Minimum value for numbers\nSCHEMA_MAX = 'maximum'  # Maximum value for numbers\nSCHEMA_ENUM = 'enum'  # Allowed values for dropdowns\nSCHEMA_MIN_LEN = 'minLength'  # Minimum string length\nSCHEMA_MAX_LEN = 'maxLength'  # Maximum string length\nSCHEMA_PATTERN = 'pattern'  # Regex pattern for strings\nSCHEMA_FORMAT = 'format'  # String format (email, uri, date, etc.)\n\n\n\nUniversal Worker (worker.ipynb)\n\nFastAPI server that runs inside isolated plugin environments\n\n\nImport\nfrom cjm_plugin_system.core.worker import (\n    EnhancedJSONEncoder,\n    parent_monitor,\n    create_app,\n    run_worker\n)\n\n\nFunctions\ndef parent_monitor(\n    ppid: int # Parent process ID to monitor\n) -&gt; None\n    \"\"\"\n    Monitor parent process and terminate self if parent dies.\n    \n    This implements the \"Suicide Pact\" pattern: if the Host process dies,\n    the Worker must terminate itself to prevent zombie processes.\n    \"\"\"\ndef create_app(\n    module_name: str, # Python module path (e.g., \"my_plugin.plugin\")\n    class_name: str   # Plugin class name (e.g., \"WhisperPlugin\")\n) -&gt; FastAPI: # Configured FastAPI application\n    \"Create FastAPI app that hosts the specified plugin.\"\ndef run_worker() -&gt; None:\n    \"\"\"CLI entry point for running the worker.\"\"\"\n    parser = argparse.ArgumentParser(description=\"Universal Plugin Worker\")\n    parser.add_argument(\"--module\", required=True, help=\"Plugin module path\")\n    parser.add_argument(\"--class\", dest=\"class_name\", required=True, help=\"Plugin class name\")\n    parser.add_argument(\"--port\", type=int, required=True, help=\"Port to listen on\")\n    parser.add_argument(\"--ppid\", type=int, required=False, help=\"Parent PID to monitor\")\n    args = parser.parse_args()\n\n    # Start watchdog if parent PID provided\n    if args.ppid\n    \"CLI entry point for running the worker.\"\n\n\nClasses\nclass EnhancedJSONEncoder(JSONEncoder):\n    \"JSON encoder that handles dataclasses and other common types.\"\n    \n    def default(\n            self,\n            o: Any # Object to encode\n        ) -&gt; Any: # JSON-serializable representation\n        \"Convert non-serializable objects to serializable form.\"",
    "crumbs": [
      "cjm-plugin-system"
    ]
  },
  {
    "objectID": "cli.html",
    "href": "cli.html",
    "title": "cli",
    "section": "",
    "text": "source",
    "crumbs": [
      "cli"
    ]
  },
  {
    "objectID": "cli.html#setup-runtime",
    "href": "cli.html#setup-runtime",
    "title": "cli",
    "section": "Setup Runtime",
    "text": "Setup Runtime\nThe setup-runtime command downloads and installs micromamba for project-local mode. This is required before running install-all when using conda_type: micromamba in the configuration.\n\nsource\n\nsetup_runtime\n\ndef setup_runtime(\n    force:bool=&lt;typer.models.OptionInfo object at 0x7fb94ed23e60&gt;\n)-&gt;None:\n\nDownload and setup micromamba runtime for project-local mode.\n\nsource\n\n\nrun_cmd\n\ndef run_cmd(\n    cmd:str, # Shell command to execute\n    check:bool=True, # Whether to raise on non-zero exit\n)-&gt;None:\n\nRun a shell command and stream output.\nUses the platform’s default shell (no hardcoded /bin/bash).\n\nsource\n\n\ninstall_all\n\ndef install_all(\n    plugins_path:str=&lt;typer.models.OptionInfo object at 0x7fb94ed3c1a0&gt;,\n    force:bool=&lt;typer.models.OptionInfo object at 0x7fb94ed3c230&gt;\n)-&gt;None:\n\nInstall and register all plugins defined in plugins.yaml.",
    "crumbs": [
      "cli"
    ]
  },
  {
    "objectID": "cli.html#setup-host-environment",
    "href": "cli.html#setup-host-environment",
    "title": "cli",
    "section": "Setup Host Environment",
    "text": "Setup Host Environment\nThe setup-host command prepares the host application’s Python environment by installing all unique interface libraries referenced in plugins.yaml. This is separate from install-all which sets up isolated plugin environments.\n\nsource\n\nsetup_host\n\ndef setup_host(\n    plugins_path:str=&lt;typer.models.OptionInfo object at 0x7fb94ed3f470&gt;,\n    yes:bool=&lt;typer.models.OptionInfo object at 0x7fb94ed3f230&gt;\n)-&gt;None:\n\nInstall interface libraries in the current Python environment.",
    "crumbs": [
      "cli"
    ]
  },
  {
    "objectID": "cli.html#estimate-disk-space",
    "href": "cli.html#estimate-disk-space",
    "title": "cli",
    "section": "Estimate Disk Space",
    "text": "Estimate Disk Space\nThe estimate-size command estimates the disk space required for plugin environments before installation. It uses conda’s dry-run feature for accurate conda package sizes and queries PyPI for pip package sizes.\n\nsource\n\nestimate_size\n\ndef estimate_size(\n    plugins_path:str=&lt;typer.models.OptionInfo object at 0x7fb94ed08050&gt;,\n    plugin_name:Optional=&lt;typer.models.OptionInfo object at 0x7fb94ed0a660&gt;,\n    verbose:bool=&lt;typer.models.OptionInfo object at 0x7fb94ed0b4d0&gt;\n)-&gt;None:\n\nEstimate disk space required for plugin environments.",
    "crumbs": [
      "cli"
    ]
  },
  {
    "objectID": "cli.html#list-plugins",
    "href": "cli.html#list-plugins",
    "title": "cli",
    "section": "List Plugins",
    "text": "List Plugins\nThe list command shows installed plugins by scanning manifest files in the configured manifests directory (defaults to ~/.cjm/manifests/). It can optionally cross-reference with a plugins.yaml file and check conda environment status.\n\nsource\n\nlist_plugins\n\ndef list_plugins(\n    plugins_path:Optional=&lt;typer.models.OptionInfo object at 0x7fb94ed3d940&gt;,\n    show_envs:bool=&lt;typer.models.OptionInfo object at 0x7fb94ed3caa0&gt;\n)-&gt;None:\n\nList installed plugins from manifest directory.",
    "crumbs": [
      "cli"
    ]
  },
  {
    "objectID": "cli.html#remove-plugin",
    "href": "cli.html#remove-plugin",
    "title": "cli",
    "section": "Remove Plugin",
    "text": "Remove Plugin\nThe remove command removes a plugin’s manifest and optionally its conda environment. It can look up the environment name from the manifest or a config file.\n\nsource\n\nremove_plugin\n\ndef remove_plugin(\n    plugin_name:str=&lt;typer.models.ArgumentInfo object at 0x7fb94ed09a60&gt;,\n    plugins_path:Optional=&lt;typer.models.OptionInfo object at 0x7fb94ed0a450&gt;,\n    keep_env:bool=&lt;typer.models.OptionInfo object at 0x7fb94ed3ce00&gt;,\n    yes:bool=&lt;typer.models.OptionInfo object at 0x7fb94ed3f4a0&gt;\n)-&gt;None:\n\nRemove a plugin’s manifest and conda environment.",
    "crumbs": [
      "cli"
    ]
  },
  {
    "objectID": "utils/validation.html",
    "href": "utils/validation.html",
    "title": "Configuration Validation",
    "section": "",
    "text": "Constants for field metadata keys used in dataclass configuration. These enable validation and are compatible with JSON schema generation for UI form builders.",
    "crumbs": [
      "utils",
      "Configuration Validation"
    ]
  },
  {
    "objectID": "utils/validation.html#schema-metadata-constants",
    "href": "utils/validation.html#schema-metadata-constants",
    "title": "Configuration Validation",
    "section": "",
    "text": "Constants for field metadata keys used in dataclass configuration. These enable validation and are compatible with JSON schema generation for UI form builders.",
    "crumbs": [
      "utils",
      "Configuration Validation"
    ]
  },
  {
    "objectID": "utils/validation.html#field-validation",
    "href": "utils/validation.html#field-validation",
    "title": "Configuration Validation",
    "section": "Field Validation",
    "text": "Field Validation\nFunctions for validating field values against metadata constraints.\n\nsource\n\nvalidate_field_value\n\ndef validate_field_value(\n    value:Any, # Value to validate\n    metadata:Dict, # Field metadata containing constraints\n    field_name:str='', # Field name for error messages\n)-&gt;Tuple: # (is_valid, error_message)\n\nValidate a value against field metadata constraints.\n\nsource\n\n\nvalidate_config\n\ndef validate_config(\n    config:Any, # Configuration dataclass instance to validate\n)-&gt;Tuple: # (is_valid, error_message)\n\nValidate all fields in a configuration dataclass against their metadata constraints.",
    "crumbs": [
      "utils",
      "Configuration Validation"
    ]
  },
  {
    "objectID": "utils/validation.html#dataclass-configuration-utilities",
    "href": "utils/validation.html#dataclass-configuration-utilities",
    "title": "Configuration Validation",
    "section": "Dataclass Configuration Utilities",
    "text": "Dataclass Configuration Utilities\nThese functions provide utilities for working with dataclass-based plugin configurations.\n\nsource\n\nconfig_to_dict\n\ndef config_to_dict(\n    config:Any, # Configuration dataclass instance\n)-&gt;Dict: # Dictionary representation of the configuration\n\nConvert a configuration dataclass instance to a dictionary.\nConverts a dataclass configuration instance to a dictionary for serialization or passing to other systems. Also accepts dict input for passthrough convenience.\n\nsource\n\n\ndict_to_config\n\ndef dict_to_config(\n    config_class:Type, # Configuration dataclass type\n    data:Optional=None, # Dictionary with configuration values\n    validate:bool=False, # Whether to validate against metadata constraints\n)-&gt;T: # Instance of the configuration dataclass\n\nCreate a configuration dataclass instance from a dictionary.\n\nsource\n\n\nextract_defaults\n\ndef extract_defaults(\n    config_class:Type, # Configuration dataclass type\n)-&gt;Dict: # Default values from the dataclass\n\nExtract default values from a configuration dataclass type.",
    "crumbs": [
      "utils",
      "Configuration Validation"
    ]
  },
  {
    "objectID": "utils/validation.html#json-schema-conversion",
    "href": "utils/validation.html#json-schema-conversion",
    "title": "Configuration Validation",
    "section": "JSON Schema Conversion",
    "text": "JSON Schema Conversion\nFunctions for converting dataclass configurations to JSON Schema format, enabling automatic form generation in UIs.\n\nsource\n\ndataclass_to_jsonschema\n\ndef dataclass_to_jsonschema(\n    cls:type, # Dataclass with field metadata\n)-&gt;Dict: # JSON schema dictionary\n\nConvert a dataclass to a JSON schema for form generation.\n\n# Test _python_type_to_json_type\nfrom typing import List, Optional\n\nassert _python_type_to_json_type(str) == {\"type\": \"string\"}\nassert _python_type_to_json_type(int) == {\"type\": \"integer\"}\nassert _python_type_to_json_type(float) == {\"type\": \"number\"}\nassert _python_type_to_json_type(bool) == {\"type\": \"boolean\"}\nassert _python_type_to_json_type(List[str]) == {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n\noptional_result = _python_type_to_json_type(Optional[int])\nassert optional_result[\"type\"] == [\"integer\", \"null\"]\n\nprint(\"Type conversion tests passed\")\n\nType conversion tests passed\n\n\n\n# Test dataclass_to_jsonschema using ExampleConfig defined below\n# (This test runs after the ExampleConfig is defined in the notebook)\ndef _test_jsonschema():\n    \"\"\"Test JSON schema generation with ExampleConfig.\"\"\"\n    schema = dataclass_to_jsonschema(ExampleConfig)\n    \n    # Check structure\n    assert schema[\"name\"] == \"ExampleConfig\"\n    assert schema[\"type\"] == \"object\"\n    assert \"properties\" in schema\n    \n    # Check field properties\n    assert schema[\"properties\"][\"model\"][\"type\"] == \"string\"\n    assert schema[\"properties\"][\"model\"][\"title\"] == \"Model\"\n    assert schema[\"properties\"][\"model\"][\"enum\"] == [\"tiny\", \"base\", \"small\", \"medium\", \"large\"]\n    assert schema[\"properties\"][\"model\"][\"default\"] == \"base\"\n    \n    assert schema[\"properties\"][\"temperature\"][\"type\"] == \"number\"\n    assert schema[\"properties\"][\"temperature\"][\"minimum\"] == 0.0\n    assert schema[\"properties\"][\"temperature\"][\"maximum\"] == 1.0\n    \n    assert schema[\"properties\"][\"batch_size\"][\"type\"] == \"integer\"\n    assert schema[\"properties\"][\"enabled\"][\"type\"] == \"boolean\"\n    assert schema[\"properties\"][\"tags\"][\"type\"] == \"array\"\n    \n    print(\"dataclass_to_jsonschema tests passed\")\n    return schema\n\n\n\nExample: Working with Configuration Dataclasses\n\nfrom dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass ExampleConfig:\n    \"\"\"Example configuration dataclass with metadata constraints.\"\"\"\n    model:str = field(\n        default=\"base\",\n        metadata={\n            SCHEMA_TITLE: \"Model\",\n            SCHEMA_DESC: \"Model size to use\",\n            SCHEMA_ENUM: [\"tiny\", \"base\", \"small\", \"medium\", \"large\"]\n        }\n    )\n    temperature:float = field(\n        default=0.0,\n        metadata={\n            SCHEMA_TITLE: \"Temperature\",\n            SCHEMA_DESC: \"Sampling temperature\",\n            SCHEMA_MIN: 0.0,\n            SCHEMA_MAX: 1.0\n        }\n    )\n    batch_size:int = field(\n        default=8,\n        metadata={\n            SCHEMA_TITLE: \"Batch Size\",\n            SCHEMA_DESC: \"Batch size for processing\",\n            SCHEMA_MIN: 1,\n            SCHEMA_MAX: 32\n        }\n    )\n    enabled:bool = field(\n        default=True,\n        metadata={SCHEMA_TITLE: \"Enabled\", SCHEMA_DESC: \"Whether feature is enabled\"}\n    )\n    tags:List[str] = field(\n        default_factory=list,\n        metadata={SCHEMA_TITLE: \"Tags\", SCHEMA_DESC: \"Optional tags\"}\n    )\n\nprint(\"ExampleConfig dataclass defined with metadata constraints\")\nprint(f\"Fields: {[f.name for f in fields(ExampleConfig)]}\")\n\nExampleConfig dataclass defined with metadata constraints\nFields: ['model', 'temperature', 'batch_size', 'enabled', 'tags']\n\n\n\n# Test extract_defaults\ndefaults = extract_defaults(ExampleConfig)\nprint(\"Default values extracted from ExampleConfig:\")\nfor k, v in defaults.items():\n    print(f\"  {k}: {v!r}\")\n\nDefault values extracted from ExampleConfig:\n  model: 'base'\n  temperature: 0.0\n  batch_size: 8\n  enabled: True\n  tags: []\n\n\n\n# Test dict_to_config with validation\nprint(\"Creating config from dictionary:\")\n\n# Valid config\nconfig1 = dict_to_config(ExampleConfig, {\"model\": \"large\", \"temperature\": 0.7}, validate=True)\nprint(f\"Valid config: {config1}\")\n\n# Config with defaults (all valid)\nconfig2 = dict_to_config(ExampleConfig, {}, validate=True)\nprint(f\"Config with defaults: {config2}\")\n\n# Test validation failure - invalid enum\ntry:\n    config_bad = dict_to_config(ExampleConfig, {\"model\": \"invalid\"}, validate=True)\nexcept ValueError as e:\n    print(f\"\\n✓ Caught invalid enum: {e}\")\n\n# Test validation failure - value below minimum\ntry:\n    config_bad = dict_to_config(ExampleConfig, {\"temperature\": -0.5}, validate=True)\nexcept ValueError as e:\n    print(f\"✓ Caught below minimum: {e}\")\n\n# Test validation failure - value above maximum\ntry:\n    config_bad = dict_to_config(ExampleConfig, {\"batch_size\": 100}, validate=True)\nexcept ValueError as e:\n    print(f\"✓ Caught above maximum: {e}\")\n\nCreating config from dictionary:\nValid config: ExampleConfig(model='large', temperature=0.7, batch_size=8, enabled=True, tags=[])\nConfig with defaults: ExampleConfig(model='base', temperature=0.0, batch_size=8, enabled=True, tags=[])\n\n✓ Caught invalid enum: model: 'invalid' is not one of ['tiny', 'base', 'small', 'medium', 'large']\n✓ Caught below minimum: temperature: -0.5 is less than minimum 0.0\n✓ Caught above maximum: batch_size: 100 is greater than maximum 32\n\n\n\n# Test validate_config directly\nprint(\"Testing validate_config:\")\n\n# Valid config\nvalid_config = ExampleConfig(model=\"small\", temperature=0.5, batch_size=16)\nis_valid, error = validate_config(valid_config)\nprint(f\"Valid config: is_valid={is_valid}, error={error}\")\n\n# Invalid config - create without validation, then validate\ninvalid_config = ExampleConfig(model=\"invalid_model\", temperature=0.5, batch_size=16)\nis_valid, error = validate_config(invalid_config)\nprint(f\"Invalid model: is_valid={is_valid}, error={error}\")\n\n# Test config_to_dict\nprint(\"\\nConverting config to dictionary:\")\nconfig_dict = config_to_dict(valid_config)\nprint(f\"As dictionary: {config_dict}\")\n\nTesting validate_config:\nValid config: is_valid=True, error=None\nInvalid model: is_valid=False, error=model: 'invalid_model' is not one of ['tiny', 'base', 'small', 'medium', 'large']\n\nConverting config to dictionary:\nAs dictionary: {'model': 'small', 'temperature': 0.5, 'batch_size': 16, 'enabled': True, 'tags': []}\n\n\n\n# Test JSON schema generation\nimport json\n\nschema = _test_jsonschema()\nprint(\"\\nGenerated JSON Schema:\")\nprint(json.dumps(schema, indent=2))\n\ndataclass_to_jsonschema tests passed\n\nGenerated JSON Schema:\n{\n  \"name\": \"ExampleConfig\",\n  \"title\": \"ExampleConfig\",\n  \"description\": \"Example configuration dataclass with metadata constraints.\",\n  \"type\": \"object\",\n  \"properties\": {\n    \"model\": {\n      \"type\": \"string\",\n      \"title\": \"Model\",\n      \"description\": \"Model size to use\",\n      \"enum\": [\n        \"tiny\",\n        \"base\",\n        \"small\",\n        \"medium\",\n        \"large\"\n      ],\n      \"default\": \"base\"\n    },\n    \"temperature\": {\n      \"type\": \"number\",\n      \"title\": \"Temperature\",\n      \"description\": \"Sampling temperature\",\n      \"minimum\": 0.0,\n      \"maximum\": 1.0,\n      \"default\": 0.0\n    },\n    \"batch_size\": {\n      \"type\": \"integer\",\n      \"title\": \"Batch Size\",\n      \"description\": \"Batch size for processing\",\n      \"minimum\": 1,\n      \"maximum\": 32,\n      \"default\": 8\n    },\n    \"enabled\": {\n      \"type\": \"boolean\",\n      \"title\": \"Enabled\",\n      \"description\": \"Whether feature is enabled\",\n      \"default\": true\n    },\n    \"tags\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"title\": \"Tags\",\n      \"description\": \"Optional tags\",\n      \"default\": []\n    }\n  }\n}",
    "crumbs": [
      "utils",
      "Configuration Validation"
    ]
  },
  {
    "objectID": "core/scheduling.html",
    "href": "core/scheduling.html",
    "title": "Scheduling",
    "section": "",
    "text": "Abstract base class that defines the scheduling policy interface. Schedulers decide whether a plugin can execute based on its resource requirements and current system state.\nThe separation of Mechanism (plugins reporting stats) from Policy (schedulers deciding allocation) allows the same plugin ecosystem to serve:\n\nInteractive web apps: Use SafetyScheduler to prevent OOM crashes\nBatch processing: Use QueueScheduler to wait for resources\nDevelopment: Use PermissiveScheduler to run everything\n\n\nsource\n\n\n\ndef ResourceScheduler(\n    args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\nAbstract base class for resource allocation policies.",
    "crumbs": [
      "core",
      "Scheduling"
    ]
  },
  {
    "objectID": "core/scheduling.html#resourcescheduler",
    "href": "core/scheduling.html#resourcescheduler",
    "title": "Scheduling",
    "section": "",
    "text": "Abstract base class that defines the scheduling policy interface. Schedulers decide whether a plugin can execute based on its resource requirements and current system state.\nThe separation of Mechanism (plugins reporting stats) from Policy (schedulers deciding allocation) allows the same plugin ecosystem to serve:\n\nInteractive web apps: Use SafetyScheduler to prevent OOM crashes\nBatch processing: Use QueueScheduler to wait for resources\nDevelopment: Use PermissiveScheduler to run everything\n\n\nsource\n\n\n\ndef ResourceScheduler(\n    args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\nAbstract base class for resource allocation policies.",
    "crumbs": [
      "core",
      "Scheduling"
    ]
  },
  {
    "objectID": "core/scheduling.html#permissivescheduler",
    "href": "core/scheduling.html#permissivescheduler",
    "title": "Scheduling",
    "section": "PermissiveScheduler",
    "text": "PermissiveScheduler\nDefault scheduler that allows all executions. Use this for development, scripting, and batch processing where you want maximum throughput without safety checks.\n\nsource\n\nPermissiveScheduler\n\ndef PermissiveScheduler(\n    args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\nScheduler that allows all executions (Default / Dev Mode).",
    "crumbs": [
      "core",
      "Scheduling"
    ]
  },
  {
    "objectID": "core/scheduling.html#safetyscheduler",
    "href": "core/scheduling.html#safetyscheduler",
    "title": "Scheduling",
    "section": "SafetyScheduler",
    "text": "SafetyScheduler\nProduction scheduler that blocks execution if resources are insufficient. Checks GPU VRAM and system RAM against plugin requirements defined in the manifest.\nResource requirements are read from the plugin manifest:\n{\n  \"resources\": {\n    \"requires_gpu\": true,\n    \"min_gpu_vram_mb\": 4096,\n    \"min_system_ram_mb\": 8192\n  }\n}\nSystem stats are provided by a System Monitor plugin implementing the cjm-infra-plugin-system interface.\n\nsource\n\nSafetyScheduler\n\ndef SafetyScheduler(\n    args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\nScheduler that prevents execution if resources are insufficient.",
    "crumbs": [
      "core",
      "Scheduling"
    ]
  },
  {
    "objectID": "core/scheduling.html#queuescheduler",
    "href": "core/scheduling.html#queuescheduler",
    "title": "Scheduling",
    "section": "QueueScheduler",
    "text": "QueueScheduler\nBatch processing scheduler that waits for resources to become available. Polls the system monitor until resources are free or timeout is reached.\n\nSync path: Uses time.sleep() for blocking wait (scripts, batch jobs)\nAsync path: Uses await asyncio.sleep() for non-blocking wait (FastHTML, async apps)\nActive tracking: Tracks which plugins have running executions via get_active_plugins()\n\nThe active plugin tracking enables smart eviction: plugins that are currently executing should never be evicted, while idle plugins can be safely released to free resources.\n\nsource\n\nQueueScheduler\n\ndef QueueScheduler(\n    timeout:float=300.0, # Max seconds to wait for resources\n    poll_interval:float=2.0, # Seconds between resource checks\n):\n\nScheduler that waits for resources to become available.",
    "crumbs": [
      "core",
      "Scheduling"
    ]
  },
  {
    "objectID": "core/scheduling.html#usage-examples",
    "href": "core/scheduling.html#usage-examples",
    "title": "Scheduling",
    "section": "Usage Examples",
    "text": "Usage Examples\n\nDevelopment Mode (Default)\nfrom cjm_plugin_system.core.manager import PluginManager\n\n# Default: PermissiveScheduler allows everything\nmanager = PluginManager()\n\n\nProduction Mode with Safety Checks\nfrom cjm_plugin_system.core.manager import PluginManager\nfrom cjm_plugin_system.core.scheduling import SafetyScheduler\n\n# Create manager with safety scheduler\nmanager = PluginManager(scheduler=SafetyScheduler())\n\n# Load plugins\nmanager.load_all()\n\n# Register a system monitor plugin for real-time stats\nmanager.register_system_monitor(\"sys-mon-nvidia\")\n\n# Execution will now check resources before running\ntry:\n    result = manager.execute_plugin(\"whisper-local\", audio=\"/path/to/audio.wav\")\nexcept RuntimeError as e:\n    print(f\"Blocked: {e}\")\n\n\nBatch Processing with Queue\nfrom cjm_plugin_system.core.manager import PluginManager\nfrom cjm_plugin_system.core.scheduling import QueueScheduler\n\n# Create manager with queue scheduler (waits up to 5 minutes)\nmanager = PluginManager(scheduler=QueueScheduler(timeout=300.0, poll_interval=5.0))\nmanager.load_all()\nmanager.register_system_monitor(\"sys-mon-nvidia\")\n\n# Will block until resources are available or timeout\nresult = manager.execute_plugin(\"whisper-local\", audio=\"/path/to/audio.wav\")\n\n\nAsync App with Queue (FastHTML)\nfrom cjm_plugin_system.core.manager import PluginManager\nfrom cjm_plugin_system.core.scheduling import QueueScheduler\n\nmanager = PluginManager(scheduler=QueueScheduler())\nmanager.load_all()\nmanager.register_system_monitor(\"sys-mon-nvidia\")\n\n# Non-blocking wait using asyncio.sleep\nresult = await manager.execute_plugin_async(\"whisper-local\", audio=\"/path/to/audio.wav\")",
    "crumbs": [
      "core",
      "Scheduling"
    ]
  },
  {
    "objectID": "core/interface.html",
    "href": "core/interface.html",
    "title": "Plugin Interface",
    "section": "",
    "text": "The FileBackedDTO protocol defines objects that can serialize themselves to disk for zero-copy transfer between Host and Worker processes. When the Proxy detects an argument implementing this protocol, it calls to_temp_file() and sends the file path instead of the data.\n\nsource\n\n\n\ndef FileBackedDTO(\n    args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\nProtocol for Data Transfer Objects that serialize to disk for zero-copy transfer.",
    "crumbs": [
      "core",
      "Plugin Interface"
    ]
  },
  {
    "objectID": "core/interface.html#filebackeddto-protocol",
    "href": "core/interface.html#filebackeddto-protocol",
    "title": "Plugin Interface",
    "section": "",
    "text": "The FileBackedDTO protocol defines objects that can serialize themselves to disk for zero-copy transfer between Host and Worker processes. When the Proxy detects an argument implementing this protocol, it calls to_temp_file() and sends the file path instead of the data.\n\nsource\n\n\n\ndef FileBackedDTO(\n    args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\nProtocol for Data Transfer Objects that serialize to disk for zero-copy transfer.",
    "crumbs": [
      "core",
      "Plugin Interface"
    ]
  },
  {
    "objectID": "core/interface.html#plugininterface",
    "href": "core/interface.html#plugininterface",
    "title": "Plugin Interface",
    "section": "PluginInterface",
    "text": "PluginInterface\nThe PluginInterface is an abstract base class that defines the contract all plugins must implement. This interface works for both:\n\nConcrete Plugins: Running in Worker processes (implement the actual logic)\nRemote Proxies: Running in Host process (forward calls over HTTP)\n\nThe interface is domain-agnostic. Domain-specific plugin systems (e.g., transcription, vision) subclass this to add their specific methods and DTOs.\n\nsource\n\nPluginInterface\n\ndef PluginInterface(\n    args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\nAbstract base class for all plugins (both local workers and remote proxies).\nThe interface provides:\n\nIdentity: name and version properties for plugin identification\nLifecycle: initialize() for configuration and cleanup() for resource release\nExecution: execute() for main logic, execute_stream() for streaming results\nConfiguration: get_config_schema() returns JSON Schema, get_current_config() returns current values\nCancellation: cancel() for cooperative cancellation (plugins opt-in by overriding)\nProgress: report_progress() to report execution progress and status messages\n\nThe default execute_stream() implementation yields a single result from execute(). Plugins can override this for true streaming where partial results are yielded as they become available.\nThe cancel() and report_progress() methods have default implementations. Plugins can override cancel() to implement cooperative cancellation. During execute(), plugins can call self.report_progress(0.5, \"Processing...\") to report progress.",
    "crumbs": [
      "core",
      "Plugin Interface"
    ]
  },
  {
    "objectID": "core/interface.html#example-implementing-a-plugin",
    "href": "core/interface.html#example-implementing-a-plugin",
    "title": "Plugin Interface",
    "section": "Example: Implementing a Plugin",
    "text": "Example: Implementing a Plugin\nHere’s a complete example showing how to implement a concrete plugin:\n\nfrom dataclasses import dataclass, field, asdict\n\n@dataclass\nclass ExampleConfig:\n    \"\"\"Configuration for the example plugin.\"\"\"\n    mode: str = \"balanced\"\n    threshold: float = 0.5\n    max_workers: int = 4\n\nclass ExamplePlugin(PluginInterface):\n    \"\"\"A simple example plugin implementation.\"\"\"\n\n    def __init__(self):\n        self._config: ExampleConfig = ExampleConfig()\n        self._resource: Optional[str] = None\n\n    @property\n    def name(self) -&gt; str:\n        return \"example-plugin\"\n    \n    @property\n    def version(self) -&gt; str:\n        return \"1.0.0\"\n    \n    def initialize(self, config: Optional[Dict[str, Any]] = None) -&gt; None:\n        \"\"\"Initialize or re-configure the plugin.\"\"\"\n        if config is None:\n            config = {}\n        \n        # Merge with defaults\n        current = asdict(self._config)\n        current.update(config)\n        self._config = ExampleConfig(**current)\n        \n        # Initialize resources based on config\n        self._resource = f\"Resource-{self._config.mode}\"\n\n    def execute(self, input_data: str, **kwargs) -&gt; str:\n        \"\"\"Process input data.\"\"\"\n        return f\"Processed '{input_data}' using {self._resource}\"\n\n    def get_config_schema(self) -&gt; Dict[str, Any]:\n        \"\"\"Return JSON Schema for configuration.\"\"\"\n        return {\n            \"type\": \"object\",\n            \"properties\": {\n                \"mode\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"fast\", \"balanced\", \"quality\"],\n                    \"default\": \"balanced\"\n                },\n                \"threshold\": {\n                    \"type\": \"number\",\n                    \"minimum\": 0.0,\n                    \"maximum\": 1.0,\n                    \"default\": 0.5\n                },\n                \"max_workers\": {\n                    \"type\": \"integer\",\n                    \"minimum\": 1,\n                    \"maximum\": 16,\n                    \"default\": 4\n                }\n            }\n        }\n\n    def get_current_config(self) -&gt; Dict[str, Any]:\n        \"\"\"Return current configuration.\"\"\"\n        return asdict(self._config)\n\n    def cleanup(self) -&gt; None:\n        \"\"\"Clean up resources.\"\"\"\n        self._resource = None\n\n\n# Test the example plugin\nplugin = ExamplePlugin()\nplugin.initialize()\n\nprint(f\"Plugin: {plugin.name} v{plugin.version}\")\nprint(f\"\\nConfig Schema:\")\nprint(plugin.get_config_schema())\nprint(f\"\\nCurrent Config:\")\nprint(plugin.get_current_config())\n\nPlugin: example-plugin v1.0.0\n\nConfig Schema:\n{'type': 'object', 'properties': {'mode': {'type': 'string', 'enum': ['fast', 'balanced', 'quality'], 'default': 'balanced'}, 'threshold': {'type': 'number', 'minimum': 0.0, 'maximum': 1.0, 'default': 0.5}, 'max_workers': {'type': 'integer', 'minimum': 1, 'maximum': 16, 'default': 4}}}\n\nCurrent Config:\n{'mode': 'balanced', 'threshold': 0.5, 'max_workers': 4}\n\n\n\n# Test execution\nresult = plugin.execute(\"sample_data\")\nprint(f\"Result: {result}\")\n\n# Test re-initialization with new config\nplugin.initialize({\"mode\": \"quality\", \"threshold\": 0.8})\nprint(f\"\\nAfter re-init config: {plugin.get_current_config()}\")\nresult = plugin.execute(\"more_data\")\nprint(f\"Result: {result}\")\n\n# Test cleanup\nplugin.cleanup()\nprint(f\"\\nAfter cleanup, resource is cleared\")\n\nResult: Processed 'sample_data' using Resource-balanced\n\nAfter re-init config: {'mode': 'quality', 'threshold': 0.8, 'max_workers': 4}\nResult: Processed 'more_data' using Resource-quality\n\nAfter cleanup, resource is cleared\n\n\n\n# Test streaming (default implementation yields single result)\nplugin.initialize({\"mode\": \"balanced\"})\n\nprint(\"Streaming execution:\")\nfor chunk in plugin.execute_stream(\"stream_data\"):\n    print(f\"  Chunk: {chunk}\")\n\nStreaming execution:\n  Chunk: Processed 'stream_data' using Resource-balanced\n\n\n\n# Test FileBackedDTO protocol detection\nimport tempfile\n\nclass MockAudioData:\n    \"\"\"Example class implementing FileBackedDTO.\"\"\"\n    \n    def __init__(self, data: bytes):\n        self._data = data\n    \n    def to_temp_file(self) -&gt; str:\n        \"\"\"Save to temp file and return path.\"\"\"\n        with tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\") as f:\n            f.write(self._data)\n            return f.name\n\n# Check if it implements the protocol\naudio = MockAudioData(b\"fake audio data\")\nprint(f\"MockAudioData implements FileBackedDTO: {isinstance(audio, FileBackedDTO)}\")\nprint(f\"Temp file path: {audio.to_temp_file()}\")\n\n# A regular string does not implement the protocol\nprint(f\"str implements FileBackedDTO: {isinstance('hello', FileBackedDTO)}\")\n\nMockAudioData implements FileBackedDTO: True\nTemp file path: /tmp/tmp4qld82pq.wav\nstr implements FileBackedDTO: False",
    "crumbs": [
      "core",
      "Plugin Interface"
    ]
  },
  {
    "objectID": "core/worker.html",
    "href": "core/worker.html",
    "title": "Universal Worker",
    "section": "",
    "text": "The Universal Worker is a FastAPI server that:",
    "crumbs": [
      "core",
      "Universal Worker"
    ]
  },
  {
    "objectID": "core/worker.html#enhancedjsonencoder",
    "href": "core/worker.html#enhancedjsonencoder",
    "title": "Universal Worker",
    "section": "EnhancedJSONEncoder",
    "text": "EnhancedJSONEncoder\nCustom JSON encoder that handles dataclasses and other common Python types that need serialization for HTTP responses.\n\nsource\n\nEnhancedJSONEncoder\n\ndef EnhancedJSONEncoder(\n    skipkeys:bool=False, ensure_ascii:bool=True, check_circular:bool=True, allow_nan:bool=True, sort_keys:bool=False,\n    indent:NoneType=None, separators:NoneType=None, default:NoneType=None\n):\n\nJSON encoder that handles dataclasses and other common types.\n\n# Test EnhancedJSONEncoder\nfrom dataclasses import dataclass\n\n@dataclass\nclass SampleConfig:\n    name: str\n    value: int\n\ncfg = SampleConfig(name=\"test\", value=42)\nresult = json.dumps(cfg, cls=EnhancedJSONEncoder)\nprint(f\"Encoded: {result}\")\nassert json.loads(result) == {\"name\": \"test\", \"value\": 42}\n\nEncoded: {\"name\": \"test\", \"value\": 42}",
    "crumbs": [
      "core",
      "Universal Worker"
    ]
  },
  {
    "objectID": "core/worker.html#pid-watchdog",
    "href": "core/worker.html#pid-watchdog",
    "title": "Universal Worker",
    "section": "PID Watchdog",
    "text": "PID Watchdog\nThe “Suicide Pact” pattern: if the Host process dies, the Worker must terminate itself to prevent zombie processes consuming resources.\n\nsource\n\nparent_monitor\n\ndef parent_monitor(\n    ppid:int, # Parent process ID to monitor\n)-&gt;None:\n\nMonitor parent process and terminate self if parent dies.\nThis implements the “Suicide Pact” pattern: if the Host process dies, the Worker must terminate itself to prevent zombie processes.\nThe watchdog runs in a daemon thread, checking every second if the parent process is still alive. When the parent dies (or becomes a zombie), the worker terminates itself using terminate_self() which handles cross-platform differences (SIGTERM on Unix, os._exit() on Windows).",
    "crumbs": [
      "core",
      "Universal Worker"
    ]
  },
  {
    "objectID": "core/worker.html#application-factory",
    "href": "core/worker.html#application-factory",
    "title": "Universal Worker",
    "section": "Application Factory",
    "text": "Application Factory\nCreates the FastAPI application with all endpoints for plugin communication.\n\nsource\n\ncreate_app\n\ndef create_app(\n    module_name:str, # Python module path (e.g., \"my_plugin.plugin\")\n    class_name:str, # Plugin class name (e.g., \"WhisperPlugin\")\n)-&gt;FastAPI: # Configured FastAPI application\n\nCreate FastAPI app that hosts the specified plugin.\n\n\nEndpoint Summary\n\n\n\nEndpoint\nMethod\nPurpose\n\n\n\n\n/health\nGET\nHealth check with PID and plugin identity\n\n\n/stats\nGET\nProcess telemetry (CPU, memory) for scheduler\n\n\n/initialize\nPOST\nConfigure/reconfigure plugin\n\n\n/config_schema\nGET\nJSON Schema for UI generation\n\n\n/config\nGET\nCurrent configuration values\n\n\n/execute\nPOST\nExecute plugin, return JSON\n\n\n/execute_stream\nPOST\nExecute with streaming NDJSON response\n\n\n/cancel\nPOST\nRequest cancellation of running execution\n\n\n/progress\nGET\nGet current execution progress and status\n\n\n/cleanup\nPOST\nRelease plugin resources",
    "crumbs": [
      "core",
      "Universal Worker"
    ]
  },
  {
    "objectID": "core/worker.html#cli-entry-point",
    "href": "core/worker.html#cli-entry-point",
    "title": "Universal Worker",
    "section": "CLI Entry Point",
    "text": "CLI Entry Point\nThe worker is launched as a subprocess with the plugin module/class and port specified via command line arguments.\n\nsource\n\nrun_worker\n\ndef run_worker(\n    \n)-&gt;None:\n\nCLI entry point for running the worker.\n\n\nUsage\nThe worker is typically launched by the RemotePluginProxy:\n# Example: Launch a Whisper plugin worker\npython -m cjm_plugin_system.core.worker \\\n    --module cjm_transcription_plugin_whisper.plugin \\\n    --class WhisperLocalPlugin \\\n    --port 12345 \\\n    --ppid 1234\nThe --ppid argument enables the suicide pact: if process 1234 dies, this worker terminates.",
    "crumbs": [
      "core",
      "Universal Worker"
    ]
  },
  {
    "objectID": "core/metadata.html",
    "href": "core/metadata.html",
    "title": "Plugin Metadata",
    "section": "",
    "text": "The PluginMeta dataclass stores metadata about a plugin, including its name, version, and runtime state.\n\nsource\n\n\n\ndef PluginMeta(\n    name:str, version:str, description:str='', author:str='', package_name:str='', category:str='', interface:str='',\n    config_schema:Optional=None, instance:Optional=None, enabled:bool=True, last_executed:float=0.0\n)-&gt;None:\n\nMetadata about a plugin.\n\n\n\n\n# Create plugin metadata\nmeta = PluginMeta(\n    name=\"example_plugin\",\n    version=\"1.0.0\",\n    description=\"An example plugin\",\n    author=\"Example Author\",\n    category=\"transcription\",\n    interface=\"cjm_transcription_plugin_system.plugin_interface.TranscriptionPlugin\",\n    config_schema={\n        \"type\": \"object\",\n        \"properties\": {\n            \"model\": {\"type\": \"string\", \"default\": \"base\"},\n            \"device\": {\"type\": \"string\", \"enum\": [\"cpu\", \"cuda\"]}\n        }\n    }\n)\n\nprint(\"PluginMeta instance:\")\nprint(meta)\nprint(f\"\\nName: {meta.name}\")\nprint(f\"Version: {meta.version}\")\nprint(f\"Category: {meta.category}\")\nprint(f\"Interface: {meta.interface}\")\nprint(f\"Config Schema: {meta.config_schema}\")\nprint(f\"Enabled: {meta.enabled}\")\nprint(f\"Instance: {meta.instance}\")\n\nPluginMeta instance:\nPluginMeta(name='example_plugin', version='1.0.0', description='An example plugin', author='Example Author', package_name='', category='transcription', interface='cjm_transcription_plugin_system.plugin_interface.TranscriptionPlugin', config_schema={'type': 'object', 'properties': {'model': {'type': 'string', 'default': 'base'}, 'device': {'type': 'string', 'enum': ['cpu', 'cuda']}}}, instance=None, enabled=True, last_executed=0.0)\n\nName: example_plugin\nVersion: 1.0.0\nCategory: transcription\nInterface: cjm_transcription_plugin_system.plugin_interface.TranscriptionPlugin\nConfig Schema: {'type': 'object', 'properties': {'model': {'type': 'string', 'default': 'base'}, 'device': {'type': 'string', 'enum': ['cpu', 'cuda']}}}\nEnabled: True\nInstance: None\n\n\n\n# Test with minimal arguments\nminimal_meta = PluginMeta(name=\"minimal\", version=\"0.1.0\")\nprint(f\"Minimal PluginMeta: {minimal_meta}\")\n\n# Test equality\nmeta_copy = PluginMeta(name=\"minimal\", version=\"0.1.0\")\nprint(f\"\\nEquality test: {minimal_meta == meta_copy}\")\n\nMinimal PluginMeta: PluginMeta(name='minimal', version='0.1.0', description='', author='', package_name='', category='', interface='', config_schema=None, instance=None, enabled=True, last_executed=0.0)\n\nEquality test: True",
    "crumbs": [
      "core",
      "Plugin Metadata"
    ]
  },
  {
    "objectID": "core/metadata.html#pluginmeta",
    "href": "core/metadata.html#pluginmeta",
    "title": "Plugin Metadata",
    "section": "",
    "text": "The PluginMeta dataclass stores metadata about a plugin, including its name, version, and runtime state.\n\nsource\n\n\n\ndef PluginMeta(\n    name:str, version:str, description:str='', author:str='', package_name:str='', category:str='', interface:str='',\n    config_schema:Optional=None, instance:Optional=None, enabled:bool=True, last_executed:float=0.0\n)-&gt;None:\n\nMetadata about a plugin.\n\n\n\n\n# Create plugin metadata\nmeta = PluginMeta(\n    name=\"example_plugin\",\n    version=\"1.0.0\",\n    description=\"An example plugin\",\n    author=\"Example Author\",\n    category=\"transcription\",\n    interface=\"cjm_transcription_plugin_system.plugin_interface.TranscriptionPlugin\",\n    config_schema={\n        \"type\": \"object\",\n        \"properties\": {\n            \"model\": {\"type\": \"string\", \"default\": \"base\"},\n            \"device\": {\"type\": \"string\", \"enum\": [\"cpu\", \"cuda\"]}\n        }\n    }\n)\n\nprint(\"PluginMeta instance:\")\nprint(meta)\nprint(f\"\\nName: {meta.name}\")\nprint(f\"Version: {meta.version}\")\nprint(f\"Category: {meta.category}\")\nprint(f\"Interface: {meta.interface}\")\nprint(f\"Config Schema: {meta.config_schema}\")\nprint(f\"Enabled: {meta.enabled}\")\nprint(f\"Instance: {meta.instance}\")\n\nPluginMeta instance:\nPluginMeta(name='example_plugin', version='1.0.0', description='An example plugin', author='Example Author', package_name='', category='transcription', interface='cjm_transcription_plugin_system.plugin_interface.TranscriptionPlugin', config_schema={'type': 'object', 'properties': {'model': {'type': 'string', 'default': 'base'}, 'device': {'type': 'string', 'enum': ['cpu', 'cuda']}}}, instance=None, enabled=True, last_executed=0.0)\n\nName: example_plugin\nVersion: 1.0.0\nCategory: transcription\nInterface: cjm_transcription_plugin_system.plugin_interface.TranscriptionPlugin\nConfig Schema: {'type': 'object', 'properties': {'model': {'type': 'string', 'default': 'base'}, 'device': {'type': 'string', 'enum': ['cpu', 'cuda']}}}\nEnabled: True\nInstance: None\n\n\n\n# Test with minimal arguments\nminimal_meta = PluginMeta(name=\"minimal\", version=\"0.1.0\")\nprint(f\"Minimal PluginMeta: {minimal_meta}\")\n\n# Test equality\nmeta_copy = PluginMeta(name=\"minimal\", version=\"0.1.0\")\nprint(f\"\\nEquality test: {minimal_meta == meta_copy}\")\n\nMinimal PluginMeta: PluginMeta(name='minimal', version='0.1.0', description='', author='', package_name='', category='', interface='', config_schema=None, instance=None, enabled=True, last_executed=0.0)\n\nEquality test: True",
    "crumbs": [
      "core",
      "Plugin Metadata"
    ]
  }
]